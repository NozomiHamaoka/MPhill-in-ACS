{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nozomi Hamaoka (Student ID: nh542)\n",
    "Programme for the report of L95\n",
    "Title: Comparative analysis and evaluation of parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import English models of SpaCy\n",
    "nlp_spacy_sm = spacy.load('en_core_web_sm')\n",
    "nlp_spacy_md = spacy.load('en_core_web_md')\n",
    "nlp_spacy_lg = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-20 21:03:33 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | ewt       |\n",
      "| pos       | ewt       |\n",
      "| lemma     | ewt       |\n",
      "| depparse  | ewt       |\n",
      "| sentiment | sstplus   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-01-20 21:03:33 INFO: Use device: cpu\n",
      "2021-01-20 21:03:33 INFO: Loading: tokenize\n",
      "2021-01-20 21:03:33 INFO: Loading: pos\n",
      "2021-01-20 21:03:34 INFO: Loading: lemma\n",
      "2021-01-20 21:03:34 INFO: Loading: depparse\n",
      "2021-01-20 21:03:36 INFO: Loading: sentiment\n",
      "2021-01-20 21:03:37 INFO: Loading: ner\n",
      "2021-01-20 21:03:38 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "#import English models of Stanza\n",
    "nlp_stanza = stanza.Pipeline('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the list of the sentences to be processed.\n",
    "No special pre-processing is required by SpaCy and Stanza "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentences to be analysed\n",
    "texts = ['The old car broke down in the car park.',\n",
    "         'At least two men broke in and stole my TV.',\n",
    "         'It was my aunt’s car which we sold at auction last year in February.',\n",
    "         'The only rabbit that I ever liked was eaten by my parents one summer.',\n",
    "         'Natural disasters – storms, flooding, hurricanes – occur infrequently but cause devastation that strains resources to breaking point.',\n",
    "         'It won’t rain but there might be snow on high ground if the temperature stays about the same over the next 24 hours.',\n",
    "         'English also has many words of more or less unique function, including interjections (oh, ah), negatives (no, not), politeness markers (please, thank you), and the existential ‘there’ (there are horses but not unicorns) among others.',\n",
    "         'The Penn Treebank tagset was culled from the original 87tag tagset for the Brown Corpus. For example the original Brown and C5 tagsets include a separate tag for each of the different forms of the verbs do (e.g. C5 tag VDD for did and VDG tag for doing), be and have.',\n",
    "         'Thus the EM-trained “pure HMM” tagger is probably best suited to cases where no training data is available, for example, when tagging languages for which no data was previously hand-tagged.',\n",
    "         'Skill without imagination is craftsmanship and gives us many useful objects such as wickerwork picnic baskets. Imagination without skill gives us modern art.',\n",
    "         'But far fewer people fully understand how the Media Lab operates, fits into MIT, and encourages such a creative environment; about half of the anniversary celebration’s program focused on simply defining what the Media Lab is.'\n",
    "        ]\n",
    "\n",
    "#Sentence numbers\n",
    "sentence_numbers = [1,2,7,8,10,12,15,17,19,21,23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy(sm-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 ms ± 10.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 -r 7\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp_spacy_sm(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy(md-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 ms ± 12.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 -r 7\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp_spacy_md(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy(lg-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 ms ± 8.53 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 -r 7\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp_spacy_lg(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.36 s ± 710 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 -r 7\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp_stanza(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of parsers and models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make comparison tables of 'pos', 'tag', 'dep', 'head' of SpaCy and stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to make comparison tables of 'pos', 'tag', 'dep', 'head' of SpaCy and stanza\n",
    "def comparison(number):\n",
    "    text = texts[number]\n",
    "    print('sentence' , number)\n",
    "\n",
    "    spacy = []\n",
    "    spacy_index = []\n",
    "    spacy_pos = []\n",
    "    spacy_tag =[]\n",
    "    spacy_dep = []\n",
    "    spacy_head = []\n",
    "\n",
    "    doc_spacy = nlp_spacy_sm(text)\n",
    "    for d in doc_spacy:\n",
    "        spacy_index.append((d.text))\n",
    "        spacy_pos.append((d.pos_))\n",
    "        spacy_tag.append((d.tag_))\n",
    "        spacy_dep.append((d.dep_))\n",
    "        spacy_head.append((d.head))\n",
    "\n",
    "    spacy.append(spacy_pos)\n",
    "    spacy.append(spacy_tag)\n",
    "    spacy.append(spacy_dep)\n",
    "    spacy.append(spacy_head)\n",
    "\n",
    "    df_spacy_sm = pd.DataFrame(spacy,\n",
    "                      index=['pos', 'tag', 'dep', 'head'],\n",
    "                      columns=spacy_index)\n",
    "    df_spacy_sm = df_spacy_sm.T\n",
    "    print(\"SpaCy_sm\")\n",
    "    print(len(spacy_index))\n",
    "    print(df_spacy_sm)\n",
    "    print('\\n')\n",
    "\n",
    "    spacy = []\n",
    "    spacy_index = []\n",
    "    spacy_pos = []\n",
    "    spacy_tag =[]\n",
    "    spacy_dep = []\n",
    "    spacy_head = []\n",
    "\n",
    "    doc_spacy = nlp_spacy_md(text)\n",
    "    for d in doc_spacy:\n",
    "        spacy_index.append((d.text))\n",
    "        spacy_pos.append((d.pos_))\n",
    "        spacy_tag.append((d.tag_))\n",
    "        spacy_dep.append((d.dep_))\n",
    "        spacy_head.append((d.head))\n",
    "\n",
    "    spacy.append(spacy_pos)\n",
    "    spacy.append(spacy_tag)\n",
    "    spacy.append(spacy_dep)\n",
    "    spacy.append(spacy_head)\n",
    "\n",
    "    df_spacy_md = pd.DataFrame(spacy,\n",
    "                      index=['pos', 'tag', 'dep', 'head'],\n",
    "                      columns=spacy_index)\n",
    "    df_spacy_md = df_spacy_md.T\n",
    "    print(\"SpaCy_md\")\n",
    "    print(len(spacy_index))\n",
    "    print(df_spacy_md)\n",
    "    print('\\n')\n",
    "\n",
    "    spacy = []\n",
    "    spacy_index = []\n",
    "    spacy_pos = []\n",
    "    spacy_tag =[]\n",
    "    spacy_dep = []\n",
    "    spacy_head = []\n",
    "\n",
    "    doc_spacy = nlp_spacy_lg(text)\n",
    "    for d in doc_spacy:\n",
    "        spacy_index.append((d.text))\n",
    "        spacy_pos.append((d.pos_))\n",
    "        spacy_tag.append((d.tag_))\n",
    "        spacy_dep.append((d.dep_))\n",
    "        spacy_head.append((d.head))\n",
    "\n",
    "    spacy.append(spacy_pos)\n",
    "    spacy.append(spacy_tag)\n",
    "    spacy.append(spacy_dep)\n",
    "    spacy.append(spacy_head)\n",
    "\n",
    "    df_spacy_lg = pd.DataFrame(spacy,\n",
    "                      index=['pos', 'tag', 'dep', 'head'],\n",
    "                      columns=spacy_index)\n",
    "    df_spacy_lg = df_spacy_lg.T\n",
    "    print(\"SpaCy_lg\")\n",
    "    print(len(spacy_index))\n",
    "    print(df_spacy_lg)\n",
    "    print('\\n')\n",
    "\n",
    "    stanza = []\n",
    "    stanza_index = []\n",
    "    stanza_pos = []\n",
    "    stanza_tag =[]\n",
    "    stanza_dep = []\n",
    "    stanza_head = []\n",
    "\n",
    "    doc_stanza = nlp_stanza(text)\n",
    "    sentence_number = len(doc_stanza.sentences)\n",
    "    \n",
    "    for i in range(sentence_number):\n",
    "        sentence = doc_stanza.sentences[i]\n",
    "        for token in sentence.tokens:\n",
    "            stanza_index.append(token.words[0].text)\n",
    "            stanza_pos.append(token.words[0].upos)\n",
    "            stanza_tag.append(token.words[0].xpos)\n",
    "            stanza_dep.append(token.words[0].deprel)\n",
    "            stanza_head.append(sentence.tokens[token.words[0].head-1].words[0].text)\n",
    "    \n",
    "    stanza.append(stanza_pos)\n",
    "    stanza.append(stanza_tag)\n",
    "    stanza.append(stanza_dep)\n",
    "    stanza.append(stanza_head)\n",
    "\n",
    "    df_stanza = pd.DataFrame(stanza,\n",
    "                      index=['pos', 'tag', 'dep', 'head'],\n",
    "                      columns=stanza_index)\n",
    "    df_stanza = df_stanza.T\n",
    "    print(\"Stanza\")\n",
    "    print(len(stanza_index))\n",
    "    print(df_stanza)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence 0\n",
      "SpaCy_sm\n",
      "10\n",
      "         pos  tag       dep   head\n",
      "The      DET   DT       det    car\n",
      "old      ADJ   JJ      amod    car\n",
      "car     NOUN   NN     nsubj  broke\n",
      "broke   VERB  VBD      ROOT  broke\n",
      "down     ADP   RP       prt  broke\n",
      "in       ADP   IN      prep  broke\n",
      "the      DET   DT       det   park\n",
      "car     NOUN   NN  compound   park\n",
      "park    NOUN   NN      pobj     in\n",
      ".      PUNCT    .     punct  broke\n",
      "\n",
      "\n",
      "SpaCy_md\n",
      "10\n",
      "         pos  tag       dep   head\n",
      "The      DET   DT       det    car\n",
      "old      ADJ   JJ      amod    car\n",
      "car     NOUN   NN     nsubj  broke\n",
      "broke   VERB  VBD      ROOT  broke\n",
      "down     ADP   RP       prt  broke\n",
      "in       ADP   IN      prep  broke\n",
      "the      DET   DT       det   park\n",
      "car     NOUN   NN  compound   park\n",
      "park    NOUN   NN      pobj     in\n",
      ".      PUNCT    .     punct  broke\n",
      "\n",
      "\n",
      "SpaCy_lg\n",
      "10\n",
      "         pos  tag       dep   head\n",
      "The      DET   DT       det    car\n",
      "old      ADJ   JJ      amod    car\n",
      "car     NOUN   NN     nsubj  broke\n",
      "broke   VERB  VBD      ROOT  broke\n",
      "down     ADP   RP       prt  broke\n",
      "in       ADP   IN      prep  broke\n",
      "the      DET   DT       det   park\n",
      "car     NOUN   NN  compound   park\n",
      "park    NOUN   NN      pobj     in\n",
      ".      PUNCT    .     punct  broke\n",
      "\n",
      "\n",
      "Stanza\n",
      "10\n",
      "         pos  tag           dep   head\n",
      "The      DET   DT           det    car\n",
      "old      ADJ   JJ          amod    car\n",
      "car     NOUN   NN         nsubj  broke\n",
      "broke   VERB  VBD          root      .\n",
      "down     ADP   RP  compound:prt  broke\n",
      "in       ADP   IN          case   park\n",
      "the      DET   DT           det   park\n",
      "car     NOUN   NN      compound   park\n",
      "park    NOUN   NN           obl  broke\n",
      ".      PUNCT    .         punct  broke\n",
      "\n",
      "\n",
      "sentence 1\n",
      "SpaCy_sm\n",
      "11\n",
      "         pos   tag     dep   head\n",
      "At       ADV    RB  advmod  least\n",
      "least    ADV   RBS  advmod    two\n",
      "two      NUM    CD  nummod    men\n",
      "men     NOUN   NNS   nsubj  broke\n",
      "broke   VERB   VBD    ROOT  broke\n",
      "in       ADP    RP     prt  broke\n",
      "and    CCONJ    CC      cc  broke\n",
      "stole   VERB   VBD    conj  broke\n",
      "my       DET  PRP$    poss     TV\n",
      "TV      NOUN    NN    dobj  stole\n",
      ".      PUNCT     .   punct  broke\n",
      "\n",
      "\n",
      "SpaCy_md\n",
      "11\n",
      "         pos   tag     dep   head\n",
      "At       ADV    RB  advmod  least\n",
      "least    ADJ   JJS  advmod    two\n",
      "two      NUM    CD  nummod    men\n",
      "men     NOUN   NNS   nsubj  broke\n",
      "broke   VERB   VBD    ROOT  broke\n",
      "in       ADP    RP     prt  broke\n",
      "and    CCONJ    CC      cc  broke\n",
      "stole   VERB   VBD    conj  broke\n",
      "my       DET  PRP$    poss     TV\n",
      "TV      NOUN    NN    dobj  stole\n",
      ".      PUNCT     .   punct  broke\n",
      "\n",
      "\n",
      "SpaCy_lg\n",
      "11\n",
      "         pos   tag     dep   head\n",
      "At       ADV    RB  advmod  least\n",
      "least    ADV   RBS  advmod    two\n",
      "two      NUM    CD  nummod    men\n",
      "men     NOUN   NNS   nsubj  broke\n",
      "broke   VERB   VBD    ROOT  broke\n",
      "in       ADP    RP     prt  broke\n",
      "and    CCONJ    CC      cc  broke\n",
      "stole   VERB   VBD    conj  broke\n",
      "my       DET  PRP$    poss     TV\n",
      "TV      NOUN    NN    dobj  stole\n",
      ".      PUNCT     .   punct  broke\n",
      "\n",
      "\n",
      "Stanza\n",
      "11\n",
      "         pos   tag        dep   head\n",
      "At       ADV    RB       case  least\n",
      "least    ADV   RBS       nmod    two\n",
      "two      NUM    CD     nummod    men\n",
      "men     NOUN   NNS      nsubj  broke\n",
      "broke   VERB   VBD       root      .\n",
      "in       ADV    RB     advmod  broke\n",
      "and    CCONJ    CC         cc  stole\n",
      "stole   VERB   VBD       conj  broke\n",
      "my      PRON  PRP$  nmod:poss     TV\n",
      "TV      NOUN    NN        obj  stole\n",
      ".      PUNCT     .      punct  broke\n",
      "\n",
      "\n",
      "sentence 2\n",
      "SpaCy_sm\n",
      "16\n",
      "            pos   tag       dep  head\n",
      "It         PRON   PRP     nsubj   was\n",
      "was         AUX   VBD      ROOT   was\n",
      "my          DET  PRP$      poss  aunt\n",
      "aunt       NOUN    NN      nmod   car\n",
      "’s         PART   POS     punct  aunt\n",
      "car        NOUN    NN      attr   was\n",
      "which       DET   WDT      dobj  sold\n",
      "we         PRON   PRP     nsubj  sold\n",
      "sold       VERB   VBD     relcl   car\n",
      "at          ADP    IN      prep  sold\n",
      "auction    NOUN    NN      pobj    at\n",
      "last        ADJ    JJ      amod  year\n",
      "year       NOUN    NN  npadvmod  sold\n",
      "in          ADP    IN      prep  sold\n",
      "February  PROPN   NNP      pobj    in\n",
      ".         PUNCT     .     punct   was\n",
      "\n",
      "\n",
      "SpaCy_md\n",
      "16\n",
      "            pos   tag       dep  head\n",
      "It         PRON   PRP     nsubj   was\n",
      "was         AUX   VBD      ROOT   was\n",
      "my          DET  PRP$      poss  aunt\n",
      "aunt       NOUN    NN      poss   car\n",
      "’s         PART   POS      case  aunt\n",
      "car        NOUN    NN      attr   was\n",
      "which       DET   WDT      dobj  sold\n",
      "we         PRON   PRP     nsubj  sold\n",
      "sold       VERB   VBD     relcl   car\n",
      "at          ADP    IN      prep  sold\n",
      "auction    NOUN    NN      pobj    at\n",
      "last        ADJ    JJ      amod  year\n",
      "year       NOUN    NN  npadvmod  sold\n",
      "in          ADP    IN      prep  sold\n",
      "February  PROPN   NNP      pobj    in\n",
      ".         PUNCT     .     punct   was\n",
      "\n",
      "\n",
      "SpaCy_lg\n",
      "16\n",
      "            pos   tag       dep  head\n",
      "It         PRON   PRP     nsubj   was\n",
      "was         AUX   VBD      ROOT   was\n",
      "my          DET  PRP$      poss  aunt\n",
      "aunt       NOUN    NN      poss   car\n",
      "’s         PART   POS      case  aunt\n",
      "car        NOUN    NN      attr   was\n",
      "which       DET   WDT      dobj  sold\n",
      "we         PRON   PRP     nsubj  sold\n",
      "sold       VERB   VBD     relcl   car\n",
      "at          ADP    IN      prep  sold\n",
      "auction    NOUN    NN      pobj    at\n",
      "last        ADJ    JJ      amod  year\n",
      "year       NOUN    NN  npadvmod  sold\n",
      "in          ADP    IN      prep  sold\n",
      "February  PROPN   NNP      pobj    in\n",
      ".         PUNCT     .     punct   was\n",
      "\n",
      "\n",
      "Stanza\n",
      "16\n",
      "            pos   tag        dep      head\n",
      "It         PRON   PRP      nsubj       car\n",
      "was         AUX   VBD        cop       car\n",
      "my         PRON  PRP$  nmod:poss      aunt\n",
      "aunt       NOUN    NN  nmod:poss       car\n",
      "’s         PART   POS       case      aunt\n",
      "car        NOUN    NN       root         .\n",
      "which      PRON   WDT        obj      sold\n",
      "we         PRON   PRP      nsubj      sold\n",
      "sold       VERB   VBD  acl:relcl       car\n",
      "at          ADP    IN       case   auction\n",
      "auction    NOUN    NN        obl      sold\n",
      "last        ADJ    JJ       amod      year\n",
      "year       NOUN    NN   obl:tmod      sold\n",
      "in          ADP    IN       case  February\n",
      "February  PROPN   NNP        obl      sold\n",
      ".         PUNCT     .      punct       car\n",
      "\n",
      "\n",
      "sentence 3\n",
      "SpaCy_sm\n",
      "15\n",
      "           pos   tag        dep     head\n",
      "The        DET    DT        det   rabbit\n",
      "only       ADJ    JJ       amod   rabbit\n",
      "rabbit    NOUN    NN  nsubjpass    eaten\n",
      "that       DET   WDT       dobj    liked\n",
      "I         PRON   PRP      nsubj    liked\n",
      "ever       ADV    RB     advmod    liked\n",
      "liked     VERB   VBD      relcl   rabbit\n",
      "was        AUX   VBD    auxpass    eaten\n",
      "eaten     VERB   VBN       ROOT    eaten\n",
      "by         ADP    IN      agent    eaten\n",
      "my         DET  PRP$       poss  parents\n",
      "parents   NOUN   NNS       pobj       by\n",
      "one        NUM    CD     nummod   summer\n",
      "summer    NOUN    NN   npadvmod    eaten\n",
      ".        PUNCT     .      punct    eaten\n",
      "\n",
      "\n",
      "SpaCy_md\n",
      "15\n",
      "           pos   tag        dep     head\n",
      "The        DET    DT        det   rabbit\n",
      "only       ADJ    JJ       amod   rabbit\n",
      "rabbit    NOUN    NN  nsubjpass    eaten\n",
      "that       DET   WDT       dobj    liked\n",
      "I         PRON   PRP      nsubj    liked\n",
      "ever       ADV    RB     advmod    liked\n",
      "liked     VERB   VBD      relcl   rabbit\n",
      "was        AUX   VBD    auxpass    eaten\n",
      "eaten     VERB   VBN       ROOT    eaten\n",
      "by         ADP    IN      agent    eaten\n",
      "my         DET  PRP$       poss  parents\n",
      "parents   NOUN   NNS       pobj       by\n",
      "one        NUM    CD     nummod   summer\n",
      "summer    NOUN    NN   npadvmod    eaten\n",
      ".        PUNCT     .      punct    eaten\n",
      "\n",
      "\n",
      "SpaCy_lg\n",
      "15\n",
      "           pos   tag        dep     head\n",
      "The        DET    DT        det   rabbit\n",
      "only       ADJ    JJ       amod   rabbit\n",
      "rabbit    NOUN    NN  nsubjpass    eaten\n",
      "that       DET   WDT       dobj    liked\n",
      "I         PRON   PRP      nsubj    liked\n",
      "ever       ADV    RB     advmod    liked\n",
      "liked     VERB   VBD      relcl   rabbit\n",
      "was        AUX   VBD    auxpass    eaten\n",
      "eaten     VERB   VBN       ROOT    eaten\n",
      "by         ADP    IN      agent    eaten\n",
      "my         DET  PRP$       poss  parents\n",
      "parents   NOUN   NNS       pobj       by\n",
      "one        NUM    CD     nummod   summer\n",
      "summer    NOUN    NN   npadvmod    eaten\n",
      ".        PUNCT     .      punct    eaten\n",
      "\n",
      "\n",
      "Stanza\n",
      "15\n",
      "           pos   tag         dep     head\n",
      "The        DET    DT         det   rabbit\n",
      "only       ADJ    JJ        amod   rabbit\n",
      "rabbit    NOUN    NN  nsubj:pass    eaten\n",
      "that      PRON   WDT         obj    liked\n",
      "I         PRON   PRP       nsubj    liked\n",
      "ever       ADV    RB      advmod    liked\n",
      "liked     VERB   VBD   acl:relcl   rabbit\n",
      "was        AUX   VBD    aux:pass    eaten\n",
      "eaten     VERB   VBN        root        .\n",
      "by         ADP    IN        case  parents\n",
      "my        PRON  PRP$   nmod:poss  parents\n",
      "parents   NOUN   NNS         obl    eaten\n",
      "one        NUM    CD      nummod   summer\n",
      "summer    NOUN    NN    obl:tmod    eaten\n",
      ".        PUNCT     .       punct    eaten\n",
      "\n",
      "\n",
      "sentence 4\n",
      "SpaCy_sm\n",
      "21\n",
      "                pos  tag     dep         head\n",
      "Natural         ADJ   JJ    amod    disasters\n",
      "disasters      NOUN  NNS   nsubj        occur\n",
      "–             PUNCT    :   punct    disasters\n",
      "storms         NOUN  NNS   appos    disasters\n",
      ",             PUNCT    ,   punct       storms\n",
      "flooding       NOUN   NN    conj       storms\n",
      ",             PUNCT    ,   punct     flooding\n",
      "hurricanes     NOUN  NNS    conj     flooding\n",
      "–             PUNCT    :   punct    disasters\n",
      "occur          VERB  VBP    ROOT        occur\n",
      "infrequently    ADV   RB  advmod        occur\n",
      "but           CCONJ   CC      cc        occur\n",
      "cause          VERB  VBP    conj        occur\n",
      "devastation    NOUN   NN    dobj        cause\n",
      "that            DET  WDT   nsubj      strains\n",
      "strains        VERB  VBZ   relcl  devastation\n",
      "resources      NOUN  NNS    dobj      strains\n",
      "to              ADP   IN    prep      strains\n",
      "breaking       NOUN   NN    amod        point\n",
      "point          NOUN   NN    pobj           to\n",
      ".             PUNCT    .   punct        occur\n",
      "\n",
      "\n",
      "SpaCy_md\n",
      "21\n",
      "                pos  tag       dep         head\n",
      "Natural         ADJ   JJ      amod    disasters\n",
      "disasters      NOUN  NNS     nsubj        occur\n",
      "–             PUNCT    :     punct    disasters\n",
      "storms         NOUN  NNS     appos    disasters\n",
      ",             PUNCT    ,     punct       storms\n",
      "flooding       NOUN   NN      conj       storms\n",
      ",             PUNCT    ,     punct     flooding\n",
      "hurricanes     NOUN  NNS      conj     flooding\n",
      "–             PUNCT    :     punct    disasters\n",
      "occur          VERB  VBP      ROOT        occur\n",
      "infrequently    ADV   RB    advmod        occur\n",
      "but           CCONJ   CC        cc        occur\n",
      "cause          VERB   VB      conj        occur\n",
      "devastation    NOUN   NN      dobj        cause\n",
      "that          SCONJ   IN     nsubj      strains\n",
      "strains        VERB  VBZ     relcl  devastation\n",
      "resources      NOUN  NNS      dobj      strains\n",
      "to              ADP   IN      prep      strains\n",
      "breaking       VERB  VBG  compound        point\n",
      "point          NOUN   NN      pobj           to\n",
      ".             PUNCT    .     punct        occur\n",
      "\n",
      "\n",
      "SpaCy_lg\n",
      "21\n",
      "                pos  tag       dep         head\n",
      "Natural         ADJ   JJ      amod    disasters\n",
      "disasters      NOUN  NNS     nsubj        occur\n",
      "–             PUNCT    :     punct    disasters\n",
      "storms         NOUN  NNS     appos    disasters\n",
      ",             PUNCT    ,     punct       storms\n",
      "flooding       NOUN   NN      conj       storms\n",
      ",             PUNCT    ,     punct     flooding\n",
      "hurricanes     NOUN  NNS      conj     flooding\n",
      "–             PUNCT    :     punct    disasters\n",
      "occur          VERB  VBP      ROOT        occur\n",
      "infrequently    ADV   RB    advmod        occur\n",
      "but           CCONJ   CC        cc        occur\n",
      "cause          VERB   VB      conj        occur\n",
      "devastation    NOUN   NN      dobj        cause\n",
      "that            DET  WDT     nsubj      strains\n",
      "strains        VERB  VBZ     relcl  devastation\n",
      "resources      NOUN  NNS      dobj      strains\n",
      "to              ADP   IN      prep      strains\n",
      "breaking       NOUN   NN  compound        point\n",
      "point          NOUN   NN      pobj           to\n",
      ".             PUNCT    .     punct        occur\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanza\n",
      "21\n",
      "                pos  tag        dep         head\n",
      "Natural         ADJ   JJ       amod    disasters\n",
      "disasters      NOUN  NNS      nsubj        occur\n",
      "–             PUNCT    ,      punct    disasters\n",
      "storms         NOUN  NNS      appos    disasters\n",
      ",             PUNCT    ,      punct     flooding\n",
      "flooding       NOUN   NN       conj       storms\n",
      ",             PUNCT    ,      punct   hurricanes\n",
      "hurricanes     NOUN  NNS       conj       storms\n",
      "–             PUNCT    ,      punct    disasters\n",
      "occur          VERB  VBP       root            .\n",
      "infrequently    ADV   RB     advmod        occur\n",
      "but           CCONJ   CC         cc        cause\n",
      "cause          VERB  VBP       conj        occur\n",
      "devastation    NOUN   NN        obj        cause\n",
      "that           PRON  WDT      nsubj      strains\n",
      "strains        VERB  VBZ  acl:relcl  devastation\n",
      "resources      NOUN  NNS        obj      strains\n",
      "to              ADP   IN       case        point\n",
      "breaking       NOUN   NN   compound        point\n",
      "point          NOUN   NN       nmod    resources\n",
      ".             PUNCT    .      punct        occur\n",
      "\n",
      "\n",
      "sentence 5\n",
      "SpaCy_sm\n",
      "25\n",
      "               pos  tag     dep         head\n",
      "It            PRON  PRP   nsubj         rain\n",
      "wo            VERB   MD     aux         rain\n",
      "n’t           PART   RB     neg         rain\n",
      "rain          VERB   VB    ROOT         rain\n",
      "but          CCONJ   CC      cc           be\n",
      "there         PRON   EX    expl           be\n",
      "might         VERB   MD     aux           be\n",
      "be             AUX   VB    ROOT           be\n",
      "snow          NOUN   NN    attr           be\n",
      "on             ADP   IN    prep         snow\n",
      "high           ADJ   JJ    amod       ground\n",
      "ground        NOUN   NN    pobj           on\n",
      "if           SCONJ   IN    mark        stays\n",
      "the            DET   DT     det  temperature\n",
      "temperature   NOUN   NN   nsubj        stays\n",
      "stays         VERB  VBZ   advcl           be\n",
      "about          ADP   IN    prep        stays\n",
      "the            DET   DT     det         same\n",
      "same           ADJ   JJ    pobj        about\n",
      "over           ADP   IN    prep        stays\n",
      "the            DET   DT     det        hours\n",
      "next           ADJ   JJ    amod        hours\n",
      "24             NUM   CD  nummod        hours\n",
      "hours         NOUN  NNS    pobj         over\n",
      ".            PUNCT    .   punct           be\n",
      "\n",
      "\n",
      "SpaCy_md\n",
      "25\n",
      "               pos  tag       dep         head\n",
      "It            PRON  PRP     nsubj         rain\n",
      "wo            VERB   MD       aux         rain\n",
      "n’t           PART   RB       neg         rain\n",
      "rain          VERB   VB      ROOT         rain\n",
      "but          CCONJ   CC        cc         rain\n",
      "there         PRON   EX      expl           be\n",
      "might         VERB   MD       aux           be\n",
      "be             AUX   VB      conj         rain\n",
      "snow          NOUN   NN      attr           be\n",
      "on             ADP   IN      prep         snow\n",
      "high           ADJ   JJ      amod       ground\n",
      "ground        NOUN   NN      pobj           on\n",
      "if           SCONJ   IN      mark        stays\n",
      "the            DET   DT       det  temperature\n",
      "temperature   NOUN   NN     nsubj        stays\n",
      "stays         VERB  VBZ     advcl           be\n",
      "about          ADP   IN    advmod         same\n",
      "the            DET   DT       det         same\n",
      "same           ADJ   JJ  npadvmod        stays\n",
      "over           ADP   IN      prep        stays\n",
      "the            DET   DT       det        hours\n",
      "next           ADJ   JJ      amod        hours\n",
      "24             NUM   CD    nummod        hours\n",
      "hours         NOUN  NNS      pobj         over\n",
      ".            PUNCT    .     punct           be\n",
      "\n",
      "\n",
      "SpaCy_lg\n",
      "25\n",
      "               pos  tag       dep         head\n",
      "It            PRON  PRP     nsubj         rain\n",
      "wo            VERB   MD       aux         rain\n",
      "n’t           PART   RB       neg         rain\n",
      "rain          VERB   VB      ROOT         rain\n",
      "but          CCONJ   CC        cc         rain\n",
      "there         PRON   EX      expl           be\n",
      "might         VERB   MD       aux           be\n",
      "be             AUX   VB      conj         rain\n",
      "snow          NOUN   NN      attr           be\n",
      "on             ADP   IN      prep         snow\n",
      "high           ADJ   JJ      amod       ground\n",
      "ground        NOUN   NN      pobj           on\n",
      "if           SCONJ   IN      mark        stays\n",
      "the            DET   DT       det  temperature\n",
      "temperature   NOUN   NN     nsubj        stays\n",
      "stays         VERB  VBZ     advcl           be\n",
      "about          ADP   IN    advmod         same\n",
      "the            DET   DT       det         same\n",
      "same           ADJ   JJ  npadvmod        stays\n",
      "over           ADP   IN      prep        stays\n",
      "the            DET   DT       det        hours\n",
      "next           ADJ   JJ      amod        hours\n",
      "24             NUM   CD    nummod        hours\n",
      "hours         NOUN  NNS      pobj         over\n",
      ".            PUNCT    .     punct           be\n",
      "\n",
      "\n",
      "Stanza\n",
      "25\n",
      "               pos  tag     dep         head\n",
      "It            PRON  PRP   nsubj         rain\n",
      "wo             AUX   MD     aux         rain\n",
      "n’t           PART   RB  advmod         rain\n",
      "rain          VERB   VB    root            .\n",
      "but          CCONJ   CC      cc           be\n",
      "there         PRON   EX    expl           be\n",
      "might          AUX   MD     aux           be\n",
      "be            VERB   VB    conj         rain\n",
      "snow          NOUN   NN   nsubj           be\n",
      "on             ADP   IN    case       ground\n",
      "high           ADJ   JJ    amod       ground\n",
      "ground        NOUN   NN    nmod         snow\n",
      "if           SCONJ   IN    mark        stays\n",
      "the            DET   DT     det  temperature\n",
      "temperature   NOUN   NN   nsubj        stays\n",
      "stays         VERB  VBZ   advcl           be\n",
      "about          ADP   IN    case         same\n",
      "the            DET   DT     det         same\n",
      "same           ADJ   JJ     obl        stays\n",
      "over           ADP   IN    case        hours\n",
      "the            DET   DT     det        hours\n",
      "next           ADJ   JJ    amod        hours\n",
      "24             NUM   CD  nummod        hours\n",
      "hours         NOUN  NNS     obl        stays\n",
      ".            PUNCT    .   punct         rain\n",
      "\n",
      "\n",
      "sentence 6\n",
      "SpaCy_sm\n",
      "53\n",
      "                 pos    tag        dep           head\n",
      "English        PROPN    NNP      nsubj            has\n",
      "also             ADV     RB     advmod            has\n",
      "has              AUX    VBZ      ccomp            are\n",
      "many             ADJ     JJ       amod          words\n",
      "words           NOUN    NNS       dobj            has\n",
      "of               ADP     IN       prep          words\n",
      "more             ADJ    JJR     advmod         unique\n",
      "or             CCONJ     CC         cc           more\n",
      "less             ADV    RBR       conj           more\n",
      "unique           ADJ     JJ       amod       function\n",
      "function        NOUN     NN       pobj             of\n",
      ",              PUNCT      ,      punct       function\n",
      "including       VERB    VBG       prep       function\n",
      "interjections   NOUN    NNS       pobj      including\n",
      "(              PUNCT  -LRB-      punct  interjections\n",
      "oh              INTJ     UH       intj  interjections\n",
      ",              PUNCT      ,      punct             oh\n",
      "ah              INTJ     UH       intj             oh\n",
      ")              PUNCT  -RRB-      punct  interjections\n",
      ",              PUNCT      ,      punct  interjections\n",
      "negatives      PROPN    NNP       conj  interjections\n",
      "(              PUNCT  -LRB-      punct      negatives\n",
      "no              INTJ     UH       intj      negatives\n",
      ",              PUNCT      ,      punct      negatives\n",
      "not             PART     RB        neg      negatives\n",
      ")              PUNCT  -RRB-      punct      negatives\n",
      ",              PUNCT      ,      punct  interjections\n",
      "politeness      NOUN     NN   compound        markers\n",
      "markers         NOUN    NNS       conj  interjections\n",
      "(              PUNCT  -LRB-      punct          thank\n",
      "please          INTJ     UH       intj          thank\n",
      ",              PUNCT      ,      punct          thank\n",
      "thank           VERB    VBP  parataxis        markers\n",
      "you             PRON    PRP       dobj          thank\n",
      ")              PUNCT  -RRB-      punct          thank\n",
      ",              PUNCT      ,      punct          thank\n",
      "and            CCONJ     CC         cc        markers\n",
      "the              DET     DT        det    existential\n",
      "existential      ADJ     JJ       conj        markers\n",
      "‘              PUNCT     ``      punct    existential\n",
      "there           PRON     EX     advmod    existential\n",
      "’              PUNCT     ''      punct    existential\n",
      "(              PUNCT  -LRB-      punct            are\n",
      "there           PRON     EX       expl            are\n",
      "are              AUX    VBP       ROOT            are\n",
      "horses          NOUN    NNS       attr            are\n",
      "but            CCONJ     CC         cc         horses\n",
      "not             PART     RB        neg       unicorns\n",
      "unicorns        NOUN    NNS       conj         horses\n",
      ")              PUNCT  -RRB-      punct         horses\n",
      "among            ADP     IN       prep         horses\n",
      "others          NOUN    NNS       pobj          among\n",
      ".              PUNCT      .      punct            are\n",
      "\n",
      "\n",
      "SpaCy_md\n",
      "53\n",
      "                 pos    tag        dep           head\n",
      "English        PROPN    NNP      nsubj            has\n",
      "also             ADV     RB     advmod            has\n",
      "has              AUX    VBZ       ROOT            has\n",
      "many             ADJ     JJ       amod          words\n",
      "words           NOUN    NNS       dobj            has\n",
      "of               ADP     IN       prep          words\n",
      "more             ADV    RBR       amod       function\n",
      "or             CCONJ     CC         cc           more\n",
      "less             ADV    RBR       conj           more\n",
      "unique           ADJ     JJ       conj           more\n",
      "function        NOUN     NN       pobj             of\n",
      ",              PUNCT      ,      punct       function\n",
      "including       VERB    VBG       prep       function\n",
      "interjections   NOUN    NNS       pobj      including\n",
      "(              PUNCT  -LRB-      punct  interjections\n",
      "oh              INTJ     UH       intj  interjections\n",
      ",              PUNCT      ,      punct             oh\n",
      "ah              INTJ     UH       intj             oh\n",
      ")              PUNCT  -RRB-      punct             oh\n",
      ",              PUNCT      ,      punct  interjections\n",
      "negatives       NOUN    NNS      appos  interjections\n",
      "(              PUNCT  -LRB-      punct             no\n",
      "no              INTJ     UH       intj            not\n",
      ",              PUNCT      ,      punct             no\n",
      "not             PART     RB      appos      negatives\n",
      ")              PUNCT  -RRB-      punct       function\n",
      ",              PUNCT      ,      punct            has\n",
      "politeness      NOUN     NN   compound        markers\n",
      "markers         NOUN    NNS      appos        English\n",
      "(              PUNCT  -LRB-      punct          thank\n",
      "please          INTJ     UH       intj          thank\n",
      ",              PUNCT      ,      punct          thank\n",
      "thank           VERB    VBP  parataxis        markers\n",
      "you             PRON    PRP       dobj          thank\n",
      ")              PUNCT  -RRB-      punct          thank\n",
      ",              PUNCT      ,      punct          thank\n",
      "and            CCONJ     CC         cc        markers\n",
      "the              DET     DT        det    existential\n",
      "existential      ADJ     JJ       conj        markers\n",
      "‘              PUNCT     ``      punct    existential\n",
      "there            ADV     RB     advmod    existential\n",
      "’              PUNCT     ''      punct    existential\n",
      "(              PUNCT  -LRB-      punct            are\n",
      "there           PRON     EX       expl            are\n",
      "are              AUX    VBP       ROOT            are\n",
      "horses          NOUN    NNS       attr            are\n",
      "but            CCONJ     CC         cc         horses\n",
      "not             PART     RB        neg       unicorns\n",
      "unicorns        NOUN    NNS       conj         horses\n",
      ")              PUNCT  -RRB-      punct         horses\n",
      "among            ADP     IN       prep            are\n",
      "others          NOUN    NNS       pobj          among\n",
      ".              PUNCT      .      punct            are\n",
      "\n",
      "\n",
      "SpaCy_lg\n",
      "53\n",
      "                 pos    tag        dep           head\n",
      "English        PROPN    NNP      nsubj            has\n",
      "also             ADV     RB     advmod            has\n",
      "has              AUX    VBZ       ROOT            has\n",
      "many             ADJ     JJ       amod          words\n",
      "words           NOUN    NNS       dobj            has\n",
      "of               ADP     IN       prep          words\n",
      "more             ADJ    JJR     advmod         unique\n",
      "or             CCONJ     CC         cc           more\n",
      "less             ADV    RBR       conj           more\n",
      "unique           ADJ     JJ       amod       function\n",
      "function        NOUN     NN       pobj             of\n",
      ",              PUNCT      ,      punct       function\n",
      "including       VERB    VBG       prep       function\n",
      "interjections   NOUN    NNS       pobj      including\n",
      "(              PUNCT  -LRB-      punct  interjections\n",
      "oh              INTJ     UH       prep  interjections\n",
      ",              PUNCT      ,      punct             oh\n",
      "ah              INTJ     UH       intj             oh\n",
      ")              PUNCT  -RRB-      punct             oh\n",
      ",              PUNCT      ,      punct  interjections\n",
      "negatives       NOUN    NNS       conj  interjections\n",
      "(              PUNCT  -LRB-      punct      negatives\n",
      "no              INTJ     UH       intj            not\n",
      ",              PUNCT      ,      punct             no\n",
      "not             PART     RB       intj      negatives\n",
      ")              PUNCT  -RRB-      punct      negatives\n",
      ",              PUNCT      ,      punct  interjections\n",
      "politeness      NOUN     NN   compound        markers\n",
      "markers         NOUN    NNS       conj  interjections\n",
      "(              PUNCT  -LRB-      punct          thank\n",
      "please          INTJ     UH       intj          thank\n",
      ",              PUNCT      ,      punct          thank\n",
      "thank           VERB    VBP  parataxis        markers\n",
      "you             PRON    PRP       dobj          thank\n",
      ")              PUNCT  -RRB-      punct          thank\n",
      ",              PUNCT      ,      punct        markers\n",
      "and            CCONJ     CC         cc        markers\n",
      "the              DET     DT        det    existential\n",
      "existential      ADJ     JJ       conj        markers\n",
      "‘              PUNCT     ``      punct    existential\n",
      "there            ADV     RB     advmod    existential\n",
      "’              PUNCT     ''      punct    existential\n",
      "(              PUNCT  -LRB-      punct            are\n",
      "there           PRON     EX       expl            are\n",
      "are              AUX    VBP       ROOT            are\n",
      "horses          NOUN    NNS       attr            are\n",
      "but            CCONJ     CC         cc         horses\n",
      "not             PART     RB        neg       unicorns\n",
      "unicorns        NOUN    NNS       conj         horses\n",
      ")              PUNCT  -RRB-      punct         horses\n",
      "among            ADP     IN       prep            are\n",
      "others          NOUN    NNS       pobj          among\n",
      ".              PUNCT      .      punct            are\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanza\n",
      "53\n",
      "                 pos    tag        dep           head\n",
      "English        PROPN    NNP      nsubj            has\n",
      "also             ADV     RB     advmod            has\n",
      "has             VERB    VBZ       root              .\n",
      "many             ADJ     JJ       amod          words\n",
      "words           NOUN    NNS        obj            has\n",
      "of               ADP     IN       case       function\n",
      "more             ADJ    JJR       amod       function\n",
      "or             CCONJ     CC         cc         unique\n",
      "less             ADV    RBR     advmod         unique\n",
      "unique           ADJ     JJ       conj           more\n",
      "function        NOUN     NN       nmod          words\n",
      ",              PUNCT      ,      punct       function\n",
      "including       VERB    VBG       case  interjections\n",
      "interjections   NOUN    NNS       nmod       function\n",
      "(              PUNCT  -LRB-      punct             ah\n",
      "oh              INTJ     UH  discourse             ah\n",
      ",              PUNCT      ,      punct             ah\n",
      "ah              INTJ     UH  discourse      negatives\n",
      ")              PUNCT  -RRB-      punct             ah\n",
      ",              PUNCT      ,      punct      negatives\n",
      "negatives       NOUN    NNS       conj          words\n",
      "(              PUNCT  -LRB-      punct            not\n",
      "no              INTJ     UH  discourse            not\n",
      ",              PUNCT      ,      punct            not\n",
      "not             PART     RB  parataxis      negatives\n",
      ")              PUNCT  -RRB-      punct            not\n",
      ",              PUNCT      ,      punct        markers\n",
      "politeness      NOUN     NN   compound        markers\n",
      "markers         NOUN    NNS  parataxis      negatives\n",
      "(              PUNCT  -LRB-      punct          thank\n",
      "please          INTJ     UH  discourse          thank\n",
      ",              PUNCT      ,      punct          thank\n",
      "thank           VERB    VBP  parataxis        markers\n",
      "you             PRON    PRP        obj          thank\n",
      ")              PUNCT  -RRB-      punct          thank\n",
      ",              PUNCT      ,      punct          there\n",
      "and            CCONJ     CC         cc          there\n",
      "the              DET     DT        det    existential\n",
      "existential      ADJ     JJ      nsubj          there\n",
      "‘              PUNCT     ``      punct          there\n",
      "there            ADV     RB       conj          thank\n",
      "’              PUNCT     ''      punct          there\n",
      "(              PUNCT  -LRB-      punct            are\n",
      "there           PRON     EX       expl            are\n",
      "are             VERB    VBP  parataxis          there\n",
      "horses          NOUN    NNS      nsubj            are\n",
      "but            CCONJ     CC         cc       unicorns\n",
      "not             PART     RB     advmod       unicorns\n",
      "unicorns        NOUN    NNS       conj         horses\n",
      ")              PUNCT  -RRB-      punct            are\n",
      "among            ADP     IN       case         others\n",
      "others          NOUN    NNS        obl            are\n",
      ".              PUNCT      .      punct            has\n",
      "\n",
      "\n",
      "sentence 7\n",
      "SpaCy_sm\n",
      "56\n",
      "             pos    tag        dep      head\n",
      "The          DET     DT        det    tagset\n",
      "Penn       PROPN    NNP   compound  Treebank\n",
      "Treebank   PROPN    NNP   compound    tagset\n",
      "tagset      NOUN     NN  nsubjpass    culled\n",
      "was          AUX    VBD    auxpass    culled\n",
      "culled      VERB    VBN       ROOT    culled\n",
      "from         ADP     IN       prep    culled\n",
      "the          DET     DT        det    tagset\n",
      "original     ADJ     JJ       amod    tagset\n",
      "87tag       NOUN     NN   compound    tagset\n",
      "tagset      NOUN     NN       pobj      from\n",
      "for          ADP     IN       prep    tagset\n",
      "the          DET     DT        det    Corpus\n",
      "Brown      PROPN    NNP   compound    Corpus\n",
      "Corpus     PROPN    NNP       pobj       for\n",
      ".          PUNCT      .      punct    culled\n",
      "For          ADP     IN       prep   include\n",
      "example     NOUN     NN       pobj       For\n",
      "the          DET     DT        det   tagsets\n",
      "original     ADJ     JJ       amod   tagsets\n",
      "Brown      PROPN    NNP       nmod   tagsets\n",
      "and        CCONJ     CC         cc     Brown\n",
      "C5         PROPN    NNP       conj     Brown\n",
      "tagsets     NOUN    NNS      nsubj   include\n",
      "include     VERB    VBP       ROOT   include\n",
      "a            DET     DT        det       tag\n",
      "separate     ADJ     JJ       amod       tag\n",
      "tag         NOUN     NN       dobj   include\n",
      "for          ADP     IN       prep       tag\n",
      "each         DET     DT       pobj       for\n",
      "of           ADP     IN       prep      each\n",
      "the          DET     DT        det     forms\n",
      "different    ADJ     JJ       amod     forms\n",
      "forms       NOUN    NNS       pobj        of\n",
      "of           ADP     IN       prep     forms\n",
      "the          DET     DT        det     verbs\n",
      "verbs       NOUN    NNS       pobj        of\n",
      "do           AUX    VBP       dobj   include\n",
      "(          PUNCT  -LRB-      punct       VDD\n",
      "e.g.         ADV     RB   compound       VDD\n",
      "C5          NOUN     NN   compound       VDD\n",
      "tag         NOUN     NN   compound       VDD\n",
      "VDD        PROPN    NNP       dobj        do\n",
      "for          ADP     IN       prep       VDD\n",
      "did         NOUN     NN       pobj       for\n",
      "and        CCONJ     CC         cc       did\n",
      "VDG        PROPN    NNP       conj       did\n",
      "tag         NOUN     NN       dobj       VDG\n",
      "for          ADP     IN       prep       tag\n",
      "doing       VERB    VBG       pobj       for\n",
      ")          PUNCT  -RRB-      punct       VDD\n",
      ",          PUNCT      ,      punct        do\n",
      "be           AUX     VB       ROOT        be\n",
      "and        CCONJ     CC         cc        be\n",
      "have         AUX     VB       conj        be\n",
      ".          PUNCT      .      punct        be\n",
      "\n",
      "\n",
      "SpaCy_md\n",
      "56\n",
      "             pos    tag        dep      head\n",
      "The          DET     DT        det    tagset\n",
      "Penn       PROPN    NNP   compound  Treebank\n",
      "Treebank   PROPN    NNP   compound    tagset\n",
      "tagset      NOUN     NN  nsubjpass    culled\n",
      "was          AUX    VBD    auxpass    culled\n",
      "culled      VERB    VBN       ROOT    culled\n",
      "from         ADP     IN       prep    culled\n",
      "the          DET     DT        det    tagset\n",
      "original     ADJ     JJ       amod    tagset\n",
      "87tag      PROPN    NNP   compound    tagset\n",
      "tagset      NOUN     NN       pobj      from\n",
      "for          ADP     IN       prep    tagset\n",
      "the          DET     DT        det    Corpus\n",
      "Brown      PROPN    NNP   compound    Corpus\n",
      "Corpus     PROPN    NNP       pobj       for\n",
      ".          PUNCT      .      punct    culled\n",
      "For          ADP     IN       prep   include\n",
      "example     NOUN     NN       pobj       For\n",
      "the          DET     DT        det   tagsets\n",
      "original     ADJ     JJ       amod   tagsets\n",
      "Brown      PROPN    NNP       nmod   tagsets\n",
      "and        CCONJ     CC         cc     Brown\n",
      "C5         PROPN    NNP       conj     Brown\n",
      "tagsets     NOUN    NNS      nsubj   include\n",
      "include     VERB    VBP       ROOT   include\n",
      "a            DET     DT        det       tag\n",
      "separate     ADJ     JJ       amod       tag\n",
      "tag         NOUN     NN       dobj   include\n",
      "for          ADP     IN       prep       tag\n",
      "each         DET     DT       pobj       for\n",
      "of           ADP     IN       prep      each\n",
      "the          DET     DT        det     forms\n",
      "different    ADJ     JJ       amod     forms\n",
      "forms       NOUN    NNS       pobj        of\n",
      "of           ADP     IN       prep     forms\n",
      "the          DET     DT        det     verbs\n",
      "verbs       NOUN    NNS       pobj        of\n",
      "do           AUX     VB       conj   include\n",
      "(          PUNCT  -LRB-      punct        do\n",
      "e.g.         ADV     RB     advmod       VDD\n",
      "C5          NOUN     NN   compound       VDD\n",
      "tag         NOUN     NN   compound       VDD\n",
      "VDD        PROPN    NNP      appos        do\n",
      "for          ADP     IN       prep       VDD\n",
      "did         NOUN     NN       pobj       for\n",
      "and        CCONJ     CC         cc       VDD\n",
      "VDG        PROPN    NNP   compound       tag\n",
      "tag         NOUN     NN       conj       VDD\n",
      "for          ADP     IN       prep       tag\n",
      "doing       VERB    VBG      pcomp       for\n",
      ")          PUNCT  -RRB-      punct       tag\n",
      ",          PUNCT      ,      punct        do\n",
      "be           AUX     VB       conj        do\n",
      "and        CCONJ     CC         cc        be\n",
      "have         AUX     VB       conj        be\n",
      ".          PUNCT      .      punct   include\n",
      "\n",
      "\n",
      "SpaCy_lg\n",
      "56\n",
      "             pos    tag        dep      head\n",
      "The          DET     DT        det    tagset\n",
      "Penn       PROPN    NNP   compound  Treebank\n",
      "Treebank   PROPN    NNP   compound    tagset\n",
      "tagset      NOUN     NN  nsubjpass    culled\n",
      "was          AUX    VBD    auxpass    culled\n",
      "culled      VERB    VBN       ROOT    culled\n",
      "from         ADP     IN       prep    culled\n",
      "the          DET     DT        det    tagset\n",
      "original     ADJ     JJ       amod     87tag\n",
      "87tag       NOUN     NN   compound    tagset\n",
      "tagset     PROPN    NNP       pobj      from\n",
      "for          ADP     IN       prep    tagset\n",
      "the          DET     DT        det    Corpus\n",
      "Brown      PROPN    NNP   compound    Corpus\n",
      "Corpus     PROPN    NNP       pobj       for\n",
      ".          PUNCT      .      punct    culled\n",
      "For          ADP     IN       prep   include\n",
      "example     NOUN     NN       pobj       For\n",
      "the          DET     DT        det   tagsets\n",
      "original     ADJ     JJ       amod   tagsets\n",
      "Brown      PROPN    NNP       nmod   tagsets\n",
      "and        CCONJ     CC         cc     Brown\n",
      "C5         PROPN    NNP       conj     Brown\n",
      "tagsets     NOUN    NNS      nsubj   include\n",
      "include     VERB    VBP       ROOT   include\n",
      "a            DET     DT        det       tag\n",
      "separate     ADJ     JJ       amod       tag\n",
      "tag         NOUN     NN       dobj   include\n",
      "for          ADP     IN       prep       tag\n",
      "each         DET     DT       pobj       for\n",
      "of           ADP     IN       prep      each\n",
      "the          DET     DT        det     forms\n",
      "different    ADJ     JJ       amod     forms\n",
      "forms       NOUN    NNS       pobj        of\n",
      "of           ADP     IN       prep     forms\n",
      "the          DET     DT        det     verbs\n",
      "verbs       NOUN    NNS       pobj        of\n",
      "do           AUX    VBP       prep       tag\n",
      "(          PUNCT  -LRB-      punct        do\n",
      "e.g.         ADV     RB     advmod       VDD\n",
      "C5          NOUN     NN   compound       VDD\n",
      "tag         NOUN     NN   compound       VDD\n",
      "VDD        PROPN    NNP      appos        do\n",
      "for          ADP     IN       prep       VDD\n",
      "did          AUX    VBD       pobj       for\n",
      "and        CCONJ     CC         cc       VDD\n",
      "VDG        PROPN    NNP   compound       tag\n",
      "tag         NOUN     NN       conj       VDD\n",
      "for          ADP     IN       prep       tag\n",
      "doing       VERB    VBG       pobj       for\n",
      ")          PUNCT  -RRB-      punct        do\n",
      ",          PUNCT      ,      punct   include\n",
      "be           AUX     VB       conj   include\n",
      "and        CCONJ     CC         cc        be\n",
      "have         AUX     VB       conj        be\n",
      ".          PUNCT      .      punct   include\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanza\n",
      "56\n",
      "             pos    tag         dep     head\n",
      "The          DET     DT         det   tagset\n",
      "Penn       PROPN    NNP    compound   tagset\n",
      "Treebank   PROPN    NNP    compound   tagset\n",
      "tagset      NOUN     NN  nsubj:pass   culled\n",
      "was          AUX    VBD    aux:pass   culled\n",
      "culled      VERB    VBN        root        .\n",
      "from         ADP     IN        case   tagset\n",
      "the          DET     DT         det   tagset\n",
      "original     ADJ     JJ        amod   tagset\n",
      "87tag       NOUN     NN    compound   tagset\n",
      "tagset      NOUN     NN         obl   culled\n",
      "for          ADP     IN        case   Corpus\n",
      "the          DET     DT         det   Corpus\n",
      "Brown      PROPN    NNP    compound   Corpus\n",
      "Corpus     PROPN    NNP        nmod   tagset\n",
      ".          PUNCT      .       punct   culled\n",
      "For          ADP     IN        case  example\n",
      "example     NOUN     NN         obl  include\n",
      "the          DET     DT         det    Brown\n",
      "original     ADJ     JJ        amod    Brown\n",
      "Brown      PROPN    NNP       nsubj  include\n",
      "and        CCONJ     CC          cc  tagsets\n",
      "C5         PROPN    NNP    compound  tagsets\n",
      "tagsets     NOUN    NNS        conj    Brown\n",
      "include     VERB    VBP        root        .\n",
      "a            DET     DT         det      tag\n",
      "separate     ADJ     JJ        amod      tag\n",
      "tag         NOUN     NN         obj  include\n",
      "for          ADP     IN        case     each\n",
      "each         DET     DT        nmod      tag\n",
      "of           ADP     IN        case    forms\n",
      "the          DET     DT         det    forms\n",
      "different    ADJ     JJ        amod    forms\n",
      "forms       NOUN    NNS        nmod     each\n",
      "of           ADP     IN        case    verbs\n",
      "the          DET     DT         det    verbs\n",
      "verbs       NOUN    NNS        nmod    forms\n",
      "do          VERB    VBP   acl:relcl      tag\n",
      "(          PUNCT  -LRB-       punct      VDD\n",
      "e.g.           X     FW      advmod      VDD\n",
      "C5          NOUN     NN    compound      VDD\n",
      "tag         NOUN     NN    compound      VDD\n",
      "VDD         NOUN     NN         obj       do\n",
      "for          ADP     IN        mark      did\n",
      "did         VERB    VBN        nmod      VDD\n",
      "and        CCONJ     CC          cc      tag\n",
      "VDG         NOUN     NN    compound      tag\n",
      "tag         NOUN     NN        conj      VDD\n",
      "for        SCONJ     IN        mark    doing\n",
      "doing       VERB    VBG         acl      tag\n",
      ")          PUNCT  -RRB-       punct      VDD\n",
      ",          PUNCT      ,       punct       be\n",
      "be          VERB     VB   parataxis  include\n",
      "and        CCONJ     CC          cc     have\n",
      "have        VERB     VB        conj       be\n",
      ".          PUNCT      .       punct  include\n",
      "\n",
      "\n",
      "sentence 8\n",
      "SpaCy_sm\n",
      "39\n",
      "              pos   tag        dep       head\n",
      "Thus          ADV    RB     advmod     suited\n",
      "the           DET    DT        det     tagger\n",
      "EM           NOUN    NN   npadvmod    trained\n",
      "-           PUNCT  HYPH      punct    trained\n",
      "trained      VERB   VBN       amod     tagger\n",
      "“           PUNCT    ``      punct     tagger\n",
      "pure          ADJ    JJ       amod        HMM\n",
      "HMM         PROPN   NNP       nmod     tagger\n",
      "”           PUNCT    ''      punct     tagger\n",
      "tagger       NOUN    NN  nsubjpass     suited\n",
      "is            AUX   VBZ    auxpass     suited\n",
      "probably      ADV    RB     advmod     suited\n",
      "best          ADV    RB     advmod     suited\n",
      "suited        ADJ    JJ       ROOT     suited\n",
      "to            ADP    IN       prep     suited\n",
      "cases        NOUN   NNS       pobj         to\n",
      "where         ADV   WRB     advmod         is\n",
      "no            DET    DT        det       data\n",
      "training     NOUN    NN   compound       data\n",
      "data         NOUN   NNS      nsubj         is\n",
      "is            AUX   VBZ      relcl      cases\n",
      "available     ADJ    JJ      acomp         is\n",
      ",           PUNCT     ,      punct     suited\n",
      "for           ADP    IN       prep     suited\n",
      "example      NOUN    NN       pobj        for\n",
      ",           PUNCT     ,      punct     suited\n",
      "when          ADV   WRB     advmod    tagging\n",
      "tagging      VERB   VBG      advcl     suited\n",
      "languages    NOUN   NNS       dobj    tagging\n",
      "for           ADP    IN       prep        was\n",
      "which         DET   WDT       pobj        for\n",
      "no            DET    DT        det       data\n",
      "data         NOUN    NN      nsubj        was\n",
      "was           AUX   VBD    auxpass     tagged\n",
      "previously    ADV    RB     advmod     tagged\n",
      "hand         NOUN    NN   npadvmod     tagged\n",
      "-           PUNCT  HYPH      punct     tagged\n",
      "tagged       VERB   VBN       amod  languages\n",
      ".           PUNCT     .      punct     suited\n",
      "\n",
      "\n",
      "SpaCy_md\n",
      "39\n",
      "              pos   tag       dep       head\n",
      "Thus          ADV    RB    advmod     suited\n",
      "the           DET    DT       det     tagger\n",
      "EM           NOUN    NN  npadvmod    trained\n",
      "-           PUNCT  HYPH     punct    trained\n",
      "trained      VERB   VBN      amod     tagger\n",
      "“           PUNCT    ``     punct     tagger\n",
      "pure          ADJ    JJ      amod        HMM\n",
      "HMM          NOUN    NN       det          “\n",
      "”           PUNCT    ''     punct     tagger\n",
      "tagger       NOUN    NN     nsubj         is\n",
      "is            AUX   VBZ   auxpass     suited\n",
      "probably      ADV    RB    advmod     suited\n",
      "best          ADV   RBS    advmod     suited\n",
      "suited        ADJ    JJ      ROOT     suited\n",
      "to            ADP    IN      prep     suited\n",
      "cases        NOUN   NNS      pobj         to\n",
      "where         ADV   WRB    advmod         is\n",
      "no            DET    DT       det       data\n",
      "training     NOUN    NN  compound       data\n",
      "data         NOUN   NNS     nsubj         is\n",
      "is            AUX   VBZ     relcl      cases\n",
      "available     ADJ    JJ     acomp         is\n",
      ",           PUNCT     ,     punct         is\n",
      "for           ADP    IN      prep         is\n",
      "example      NOUN    NN      pobj        for\n",
      ",           PUNCT     ,     punct         is\n",
      "when          ADV   WRB    advmod    tagging\n",
      "tagging      VERB   VBG     advcl         is\n",
      "languages    NOUN   NNS      dobj    tagging\n",
      "for           ADP    IN      prep        was\n",
      "which         DET   WDT      pobj        for\n",
      "no            DET    DT       det       data\n",
      "data         NOUN    NN     nsubj        was\n",
      "was           AUX   VBD     relcl  languages\n",
      "previously    ADV    RB    advmod        was\n",
      "hand         NOUN    NN  npadvmod     tagged\n",
      "-           PUNCT  HYPH     punct     tagged\n",
      "tagged       VERB   VBN     acomp        was\n",
      ".           PUNCT     .     punct     suited\n",
      "\n",
      "\n",
      "SpaCy_lg\n",
      "39\n",
      "              pos   tag       dep       head\n",
      "Thus          ADV    RB    advmod         is\n",
      "the           DET    DT       det     tagger\n",
      "EM          PROPN   NNP  npadvmod    trained\n",
      "-           PUNCT  HYPH     punct    trained\n",
      "trained      VERB   VBN      amod     tagger\n",
      "“           PUNCT    ``     punct     tagger\n",
      "pure          ADJ    JJ      amod     tagger\n",
      "HMM          NOUN    NN      nmod     tagger\n",
      "”           PUNCT    ''     punct     tagger\n",
      "tagger       NOUN    NN     nsubj         is\n",
      "is            AUX   VBZ      ROOT         is\n",
      "probably      ADV    RB    advmod         is\n",
      "best          ADV    RB    advmod     suited\n",
      "suited        ADJ    JJ     acomp         is\n",
      "to            ADP    IN      prep     suited\n",
      "cases        NOUN   NNS      pobj         to\n",
      "where         ADV   WRB    advmod         is\n",
      "no            DET    DT       det       data\n",
      "training     NOUN    NN  compound       data\n",
      "data         NOUN   NNS     nsubj         is\n",
      "is            AUX   VBZ     relcl      cases\n",
      "available     ADJ    JJ     acomp         is\n",
      ",           PUNCT     ,     punct         is\n",
      "for           ADP    IN      prep         is\n",
      "example      NOUN    NN      pobj        for\n",
      ",           PUNCT     ,     punct         is\n",
      "when          ADV   WRB    advmod    tagging\n",
      "tagging      VERB   VBG     advcl         is\n",
      "languages    NOUN   NNS      dobj    tagging\n",
      "for           ADP    IN      prep        was\n",
      "which         DET   WDT      pobj        for\n",
      "no            DET    DT       det       data\n",
      "data         NOUN    NN     nsubj        was\n",
      "was           AUX   VBD     relcl  languages\n",
      "previously    ADV    RB    advmod        was\n",
      "hand         NOUN    NN  npadvmod     tagged\n",
      "-           PUNCT  HYPH     punct     tagged\n",
      "tagged       VERB   VBN     acomp        was\n",
      ".           PUNCT     .     punct         is\n",
      "\n",
      "\n",
      "Stanza\n",
      "39\n",
      "              pos   tag         dep       head\n",
      "Thus          ADV    RB      advmod     suited\n",
      "the           DET    DT         det     tagger\n",
      "EM          PROPN   NNP   obl:npmod    trained\n",
      "-           PUNCT  HYPH       punct    trained\n",
      "trained      VERB   VBN        amod     tagger\n",
      "“           PUNCT    ``       punct        HMM\n",
      "pure          ADJ    JJ        amod     tagger\n",
      "HMM          INTJ    UH       appos     tagger\n",
      "”           PUNCT    ''       punct        HMM\n",
      "tagger       NOUN    NN  nsubj:pass     suited\n",
      "is            AUX   VBZ    aux:pass     suited\n",
      "probably      ADV    RB      advmod     suited\n",
      "best          ADV   RBS      advmod     suited\n",
      "suited       VERB   VBN        root          .\n",
      "to            ADP    IN        case      cases\n",
      "cases        NOUN   NNS         obl     suited\n",
      "where         ADV   WRB      advmod  available\n",
      "no            DET    DT         det       data\n",
      "training     NOUN    NN    compound       data\n",
      "data         NOUN    NN       nsubj  available\n",
      "is            AUX   VBZ         cop  available\n",
      "available     ADJ    JJ   acl:relcl      cases\n",
      ",           PUNCT     ,       punct  available\n",
      "for           ADP    IN        case    example\n",
      "example      NOUN    NN         obl  available\n",
      ",           PUNCT     ,       punct  available\n",
      "when          ADV   WRB        mark    tagging\n",
      "tagging      VERB   VBG       advcl  available\n",
      "languages    NOUN   NNS         obj    tagging\n",
      "for           ADP    IN        case      which\n",
      "which        PRON   WDT         obl     tagged\n",
      "no            DET    DT         det       data\n",
      "data         NOUN    NN  nsubj:pass     tagged\n",
      "was           AUX   VBD    aux:pass     tagged\n",
      "previously    ADV    RB      advmod     tagged\n",
      "hand         NOUN    NN   obl:npmod     tagged\n",
      "-           PUNCT  HYPH       punct     tagged\n",
      "tagged       VERB   VBN   acl:relcl  languages\n",
      ".           PUNCT     .       punct     suited\n",
      "\n",
      "\n",
      "sentence 9\n",
      "SpaCy_sm\n",
      "25\n",
      "                 pos  tag       dep         head\n",
      "Skill           NOUN   NN     nsubj           is\n",
      "without          ADP   IN      prep        Skill\n",
      "imagination     NOUN   NN      pobj      without\n",
      "is               AUX  VBZ      ROOT           is\n",
      "craftsmanship   NOUN   NN     acomp           is\n",
      "and            CCONJ   CC        cc           is\n",
      "gives           VERB  VBZ      conj           is\n",
      "us              PRON  PRP    dative        gives\n",
      "many             ADJ   JJ      amod      objects\n",
      "useful           ADJ   JJ      amod      objects\n",
      "objects         NOUN  NNS      dobj        gives\n",
      "such             ADJ   JJ      amod           as\n",
      "as             SCONJ   IN      prep      objects\n",
      "wickerwork      NOUN   NN  compound       picnic\n",
      "picnic          NOUN   NN  compound      baskets\n",
      "baskets         NOUN  NNS      pobj           as\n",
      ".              PUNCT    .     punct           is\n",
      "Imagination     NOUN   NN     nsubj        gives\n",
      "without          ADP   IN      prep  Imagination\n",
      "skill           NOUN   NN      pobj      without\n",
      "gives           VERB  VBZ      ROOT        gives\n",
      "us              PRON  PRP    dative        gives\n",
      "modern           ADJ   JJ      amod          art\n",
      "art             NOUN   NN      dobj        gives\n",
      ".              PUNCT    .     punct        gives\n",
      "\n",
      "\n",
      "SpaCy_md\n",
      "25\n",
      "                 pos  tag       dep         head\n",
      "Skill           NOUN   NN     nsubj           is\n",
      "without          ADP   IN      prep        Skill\n",
      "imagination     NOUN   NN      pobj      without\n",
      "is               AUX  VBZ      ROOT           is\n",
      "craftsmanship   NOUN   NN     acomp           is\n",
      "and            CCONJ   CC        cc           is\n",
      "gives           VERB  VBZ      conj           is\n",
      "us              PRON  PRP    dative        gives\n",
      "many             ADJ   JJ      amod      objects\n",
      "useful           ADJ   JJ      amod      objects\n",
      "objects         NOUN  NNS      dobj        gives\n",
      "such             ADJ   JJ      amod           as\n",
      "as             SCONJ   IN      prep      objects\n",
      "wickerwork      NOUN   NN  compound      baskets\n",
      "picnic          NOUN   NN  compound      baskets\n",
      "baskets         NOUN  NNS      pobj           as\n",
      ".              PUNCT    .     punct           is\n",
      "Imagination     NOUN   NN     nsubj        gives\n",
      "without          ADP   IN      prep  Imagination\n",
      "skill           NOUN   NN      pobj      without\n",
      "gives           VERB  VBZ      ROOT        gives\n",
      "us              PRON  PRP    dative        gives\n",
      "modern           ADJ   JJ      amod          art\n",
      "art             NOUN   NN      dobj        gives\n",
      ".              PUNCT    .     punct        gives\n",
      "\n",
      "\n",
      "SpaCy_lg\n",
      "25\n",
      "                 pos  tag       dep         head\n",
      "Skill           NOUN   NN     nsubj           is\n",
      "without          ADP   IN      prep        Skill\n",
      "imagination     NOUN   NN      pobj      without\n",
      "is               AUX  VBZ      ROOT           is\n",
      "craftsmanship   NOUN   NN      attr           is\n",
      "and            CCONJ   CC        cc           is\n",
      "gives           VERB  VBZ      conj           is\n",
      "us              PRON  PRP    dative        gives\n",
      "many             ADJ   JJ      amod      objects\n",
      "useful           ADJ   JJ      amod      objects\n",
      "objects         NOUN  NNS      dobj        gives\n",
      "such             ADJ   JJ      amod           as\n",
      "as             SCONJ   IN      prep      objects\n",
      "wickerwork      NOUN   NN  compound      baskets\n",
      "picnic          NOUN   NN  compound      baskets\n",
      "baskets         NOUN  NNS      pobj           as\n",
      ".              PUNCT    .     punct           is\n",
      "Imagination     NOUN   NN     nsubj        gives\n",
      "without          ADP   IN      prep  Imagination\n",
      "skill           NOUN   NN      pobj      without\n",
      "gives           VERB  VBZ      ROOT        gives\n",
      "us              PRON  PRP    dative        gives\n",
      "modern           ADJ   JJ      amod          art\n",
      "art             NOUN   NN      dobj        gives\n",
      ".              PUNCT    .     punct        gives\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanza\n",
      "25\n",
      "                 pos  tag       dep           head\n",
      "Skill           NOUN   NN     nsubj  craftsmanship\n",
      "without          ADP   IN      case    imagination\n",
      "imagination     NOUN   NN      nmod          Skill\n",
      "is               AUX  VBZ       cop  craftsmanship\n",
      "craftsmanship   NOUN   NN      root              .\n",
      "and            CCONJ   CC        cc          gives\n",
      "gives           VERB  VBZ      conj  craftsmanship\n",
      "us              PRON  PRP      iobj          gives\n",
      "many             ADJ   JJ      amod        objects\n",
      "useful           ADJ   JJ      amod        objects\n",
      "objects         NOUN  NNS       obj          gives\n",
      "such             ADJ   JJ      case        baskets\n",
      "as               ADP   IN     fixed           such\n",
      "wickerwork       ADJ   JJ      amod        baskets\n",
      "picnic          NOUN   NN  compound        baskets\n",
      "baskets         NOUN  NNS      nmod        objects\n",
      ".              PUNCT    .     punct  craftsmanship\n",
      "Imagination     NOUN   NN     nsubj          gives\n",
      "without          ADP   IN      case          skill\n",
      "skill           NOUN   NN      nmod    Imagination\n",
      "gives           VERB  VBZ      root              .\n",
      "us              PRON  PRP      iobj          gives\n",
      "modern           ADJ   JJ      amod            art\n",
      "art             NOUN   NN       obj          gives\n",
      ".              PUNCT    .     punct          gives\n",
      "\n",
      "\n",
      "sentence 10\n",
      "SpaCy_sm\n",
      "41\n",
      "               pos  tag       dep         head\n",
      "But          CCONJ   CC        cc   understand\n",
      "far            ADV   RB    advmod        fewer\n",
      "fewer          ADJ  JJR      amod       people\n",
      "people        NOUN  NNS     nsubj   understand\n",
      "fully          ADV   RB    advmod   understand\n",
      "understand    VERB  VBP     ccomp      focused\n",
      "how            ADV  WRB    advmod     operates\n",
      "the            DET   DT       det          Lab\n",
      "Media        PROPN  NNP  compound          Lab\n",
      "Lab          PROPN  NNP     nsubj     operates\n",
      "operates      VERB  VBZ     ccomp   understand\n",
      ",            PUNCT    ,     punct     operates\n",
      "fits          VERB  VBZ     ccomp   understand\n",
      "into           ADP   IN      prep         fits\n",
      "MIT          PROPN  NNP      pobj         into\n",
      ",            PUNCT    ,     punct   understand\n",
      "and          CCONJ   CC        cc   understand\n",
      "encourages    VERB  VBZ      conj   understand\n",
      "such           DET  PDT    predet  environment\n",
      "a              DET   DT       det  environment\n",
      "creative       ADJ   JJ      amod  environment\n",
      "environment   NOUN   NN      dobj   encourages\n",
      ";            PUNCT    :     punct      focused\n",
      "about          ADP   IN  quantmod         half\n",
      "half          NOUN   NN     nsubj      focused\n",
      "of             ADP   IN      prep         half\n",
      "the            DET   DT       det  celebration\n",
      "anniversary   NOUN   NN  compound  celebration\n",
      "celebration   NOUN   NN      pobj           of\n",
      "’s            PART  POS     punct         half\n",
      "program       NOUN   NN     appos         half\n",
      "focused       VERB  VBD      ROOT      focused\n",
      "on             ADP   IN      prep      focused\n",
      "simply         ADV   RB    advmod     defining\n",
      "defining      VERB  VBG     pcomp           on\n",
      "what          PRON   WP      attr           is\n",
      "the            DET   DT       det          Lab\n",
      "Media        PROPN  NNP  compound          Lab\n",
      "Lab          PROPN  NNP     nsubj           is\n",
      "is             AUX  VBZ     ccomp     defining\n",
      ".            PUNCT    .     punct      focused\n",
      "\n",
      "\n",
      "SpaCy_md\n",
      "41\n",
      "               pos  tag       dep         head\n",
      "But          CCONJ   CC        cc   understand\n",
      "far            ADV   RB    advmod        fewer\n",
      "fewer          ADJ  JJR      amod       people\n",
      "people        NOUN  NNS     nsubj   understand\n",
      "fully          ADV   RB    advmod   understand\n",
      "understand    VERB  VBP     ccomp      focused\n",
      "how            ADV  WRB    advmod     operates\n",
      "the            DET   DT       det          Lab\n",
      "Media        PROPN  NNP  compound          Lab\n",
      "Lab          PROPN  NNP     nsubj     operates\n",
      "operates      VERB  VBZ     ccomp   understand\n",
      ",            PUNCT    ,     punct   understand\n",
      "fits          VERB  VBZ      conj   understand\n",
      "into           ADP   IN      prep         fits\n",
      "MIT          PROPN  NNP      pobj         into\n",
      ",            PUNCT    ,     punct         fits\n",
      "and          CCONJ   CC        cc         fits\n",
      "encourages    VERB  VBZ      conj         fits\n",
      "such           DET  PDT    predet  environment\n",
      "a              DET   DT       det  environment\n",
      "creative       ADJ   JJ      amod  environment\n",
      "environment   NOUN   NN      dobj   encourages\n",
      ";            PUNCT    :     punct      focused\n",
      "about          ADP   IN    advmod         half\n",
      "half          NOUN   NN     nsubj      focused\n",
      "of             ADP   IN      prep         half\n",
      "the            DET   DT       det  celebration\n",
      "anniversary   NOUN   NN  compound  celebration\n",
      "celebration   NOUN   NN      poss      program\n",
      "’s            PART  POS      case  celebration\n",
      "program       NOUN   NN      pobj           of\n",
      "focused       VERB  VBD      ROOT      focused\n",
      "on             ADP   IN      prep      focused\n",
      "simply         ADV   RB    advmod     defining\n",
      "defining      VERB  VBG     pcomp           on\n",
      "what          PRON   WP      attr           is\n",
      "the            DET   DT       det          Lab\n",
      "Media        PROPN  NNP  compound          Lab\n",
      "Lab          PROPN  NNP     nsubj           is\n",
      "is             AUX  VBZ     ccomp     defining\n",
      ".            PUNCT    .     punct      focused\n",
      "\n",
      "\n",
      "SpaCy_lg\n",
      "41\n",
      "               pos   tag       dep         head\n",
      "But          CCONJ    CC        cc   understand\n",
      "far            ADV    RB    advmod        fewer\n",
      "fewer          ADJ   JJR      amod       people\n",
      "people        NOUN   NNS     nsubj   understand\n",
      "fully          ADV    RB    advmod   understand\n",
      "understand    VERB   VBP     ccomp      focused\n",
      "how            ADV   WRB    advmod     operates\n",
      "the            DET    DT       det          Lab\n",
      "Media        PROPN  NNPS  compound          Lab\n",
      "Lab          PROPN   NNP     nsubj     operates\n",
      "operates      VERB   VBZ     ccomp   understand\n",
      ",            PUNCT     ,     punct     operates\n",
      "fits          VERB   VBZ      conj   understand\n",
      "into           ADP    IN      prep         fits\n",
      "MIT          PROPN   NNP      pobj         into\n",
      ",            PUNCT     ,     punct         fits\n",
      "and          CCONJ    CC        cc         fits\n",
      "encourages    VERB   VBZ      conj         fits\n",
      "such           DET   PDT    predet  environment\n",
      "a              DET    DT       det  environment\n",
      "creative       ADJ    JJ      amod  environment\n",
      "environment   NOUN    NN      dobj   encourages\n",
      ";            PUNCT     :     punct      focused\n",
      "about          ADP    IN  quantmod         half\n",
      "half          NOUN    NN     nsubj      focused\n",
      "of             ADP    IN      prep         half\n",
      "the            DET    DT       det  celebration\n",
      "anniversary   NOUN    NN  compound  celebration\n",
      "celebration   NOUN    NN      poss      program\n",
      "’s            PART   POS      case  celebration\n",
      "program       NOUN    NN      pobj           of\n",
      "focused       VERB   VBD      ROOT      focused\n",
      "on             ADP    IN      prep      focused\n",
      "simply         ADV    RB    advmod     defining\n",
      "defining      VERB   VBG     pcomp           on\n",
      "what          PRON    WP      attr           is\n",
      "the            DET    DT       det          Lab\n",
      "Media        PROPN  NNPS  compound          Lab\n",
      "Lab          PROPN   NNP     nsubj           is\n",
      "is             AUX   VBZ     ccomp     defining\n",
      ".            PUNCT     .     punct      focused\n",
      "\n",
      "\n",
      "Stanza\n",
      "41\n",
      "               pos  tag         dep         head\n",
      "But          CCONJ   CC          cc   encourages\n",
      "far            ADV   RB      advmod        fewer\n",
      "fewer          ADJ  JJR        amod       people\n",
      "people        NOUN  NNS       nsubj   understand\n",
      "fully          ADV   RB      advmod   understand\n",
      "understand    VERB  VBP        root            .\n",
      "how            ADV  WRB      advmod     operates\n",
      "the            DET   DT         det          Lab\n",
      "Media         NOUN   NN    compound          Lab\n",
      "Lab          PROPN  NNP       nsubj     operates\n",
      "operates      VERB  VBZ       ccomp   understand\n",
      ",            PUNCT    ,       punct         fits\n",
      "fits          VERB  VBZ        conj     operates\n",
      "into           ADP   IN        case          MIT\n",
      "MIT          PROPN  NNP         obl         fits\n",
      ",            PUNCT    ,       punct   encourages\n",
      "and          CCONJ   CC          cc   encourages\n",
      "encourages    VERB  VBZ        conj     operates\n",
      "such           DET  PDT  det:predet  environment\n",
      "a              DET   DT         det  environment\n",
      "creative       ADJ   JJ        amod  environment\n",
      "environment   NOUN   NN         obj   encourages\n",
      ";            PUNCT    ,       punct   encourages\n",
      "about          ADV   RB      advmod         half\n",
      "half          NOUN   NN         obj   encourages\n",
      "of             ADP   IN        case      program\n",
      "the            DET   DT         det  celebration\n",
      "anniversary    ADJ   JJ        amod  celebration\n",
      "celebration   NOUN   NN   nmod:poss      program\n",
      "’s            PART  POS        case  celebration\n",
      "program       NOUN   NN        nmod         half\n",
      "focused       VERB  VBN         acl      program\n",
      "on           SCONJ   IN        mark     defining\n",
      "simply         ADV   RB      advmod     defining\n",
      "defining      VERB  VBG       advcl      focused\n",
      "what          PRON   WP       ccomp     defining\n",
      "the            DET   DT         det          Lab\n",
      "Media         NOUN   NN    compound          Lab\n",
      "Lab           NOUN   NN       nsubj         what\n",
      "is             AUX  VBZ         cop         what\n",
      ".            PUNCT    .       punct   understand\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Impriment the comparison method\n",
    "for i in range(len(texts)):\n",
    "    comparison(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make comparison tables of \"Relation\" of SpaCy and Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to make comparison tables of \"relation\" of SpaCy and Stanza\n",
    "def comparison_dep(number):\n",
    "    text = texts[number]\n",
    "    print('sentence' , number)    \n",
    "\n",
    "    spacy = []\n",
    "    spacy_index = []\n",
    "    spacy_pos = []\n",
    "    spacy_tag =[]\n",
    "    spacy_dep = []\n",
    "    spacy_head = []\n",
    "\n",
    "    doc_spacy = nlp_spacy_sm(text)\n",
    "    for d in doc_spacy:\n",
    "        spacy_index.append((d.text))\n",
    "        spacy_pos.append((d.pos_))\n",
    "        spacy_tag.append((d.tag_))\n",
    "        spacy_dep.append((d.dep_))\n",
    "        spacy_head.append((d.head))\n",
    "\n",
    "    spacy.append(spacy_pos)\n",
    "    spacy.append(spacy_tag)\n",
    "    spacy.append(spacy_dep)\n",
    "    spacy.append(spacy_head)\n",
    "\n",
    "    df_spacy_sm = pd.DataFrame(spacy,\n",
    "                      index=['pos', 'tag', 'dep', 'head'],\n",
    "                      columns=spacy_index)\n",
    "    df_spacy_sm = df_spacy_sm.T\n",
    "\n",
    "    spacy = []\n",
    "    spacy_index = []\n",
    "    spacy_pos = []\n",
    "    spacy_tag =[]\n",
    "    spacy_dep = []\n",
    "    spacy_head = []\n",
    "\n",
    "    doc_spacy = nlp_spacy_md(text)\n",
    "    for d in doc_spacy:\n",
    "        spacy_index.append((d.text))\n",
    "        spacy_pos.append((d.pos_))\n",
    "        spacy_tag.append((d.tag_))\n",
    "        spacy_dep.append((d.dep_))\n",
    "        spacy_head.append((d.head))\n",
    "\n",
    "    spacy.append(spacy_pos)\n",
    "    spacy.append(spacy_tag)\n",
    "    spacy.append(spacy_dep)\n",
    "    spacy.append(spacy_head)\n",
    "\n",
    "    df_spacy_md = pd.DataFrame(spacy,\n",
    "                      index=['pos', 'tag', 'dep', 'head'],\n",
    "                      columns=spacy_index)\n",
    "    df_spacy_md = df_spacy_md.T\n",
    "\n",
    "    spacy = []\n",
    "    spacy_index = []\n",
    "    spacy_pos = []\n",
    "    spacy_tag =[]\n",
    "    spacy_dep = []\n",
    "    spacy_head = []\n",
    "\n",
    "    doc_spacy = nlp_spacy_lg(text)\n",
    "    for d in doc_spacy:\n",
    "        spacy_index.append((d.text))\n",
    "        spacy_pos.append((d.pos_))\n",
    "        spacy_tag.append((d.tag_))\n",
    "        spacy_dep.append((d.dep_))\n",
    "        spacy_head.append((d.head))\n",
    "\n",
    "    spacy.append(spacy_pos)\n",
    "    spacy.append(spacy_tag)\n",
    "    spacy.append(spacy_dep)\n",
    "    spacy.append(spacy_head)\n",
    "\n",
    "    df_spacy_lg = pd.DataFrame(spacy,\n",
    "                      index=['pos', 'tag', 'dep', 'head'],\n",
    "                      columns=spacy_index)\n",
    "    df_spacy_lg = df_spacy_lg.T\n",
    "\n",
    "    stanza = []\n",
    "    stanza_index = []\n",
    "    stanza_pos = []\n",
    "    stanza_tag =[]\n",
    "    stanza_dep = []\n",
    "    stanza_head = []\n",
    "\n",
    "    doc_stanza = nlp_stanza(text)\n",
    "    sentence_number = len(doc_stanza.sentences)\n",
    "    \n",
    "    for i in range(sentence_number):\n",
    "        sentence = doc_stanza.sentences[i]\n",
    "        for token in sentence.tokens:\n",
    "            stanza_index.append(token.words[0].text)\n",
    "            stanza_pos.append(token.words[0].upos)\n",
    "            stanza_tag.append(token.words[0].xpos)\n",
    "            stanza_dep.append(token.words[0].deprel)\n",
    "            stanza_head.append(sentence.tokens[token.words[0].head-1].words[0].text)\n",
    "    \n",
    "    stanza.append(stanza_pos)\n",
    "    stanza.append(stanza_tag)\n",
    "    stanza.append(stanza_dep)\n",
    "    stanza.append(stanza_head)\n",
    "\n",
    "    df_stanza = pd.DataFrame(stanza,\n",
    "                      index=['pos', 'tag', 'dep', 'head'],\n",
    "                      columns=stanza_index)\n",
    "    df_stanza = df_stanza.T\n",
    "    \n",
    "    df_dep = pd.concat([df_spacy_sm['dep'], df_spacy_md['dep'],df_spacy_lg['dep'], df_stanza['dep']], axis=1, join='outer')\n",
    "    df_dep.columns = ['SpaCy_sm', 'SpaCy_md', 'SpaCy_lg', 'Stanza']\n",
    "    print(df_dep)\n",
    "    print('length = ',len(df_dep))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence 0\n",
      "       SpaCy_sm  SpaCy_md  SpaCy_lg        Stanza\n",
      "The         det       det       det           det\n",
      "old        amod      amod      amod          amod\n",
      "car       nsubj     nsubj     nsubj         nsubj\n",
      "broke      ROOT      ROOT      ROOT          root\n",
      "down        prt       prt       prt  compound:prt\n",
      "in         prep      prep      prep          case\n",
      "the         det       det       det           det\n",
      "car    compound  compound  compound      compound\n",
      "park       pobj      pobj      pobj           obl\n",
      ".         punct     punct     punct         punct\n",
      "length =  10\n",
      "\n",
      "\n",
      "sentence 1\n",
      "      SpaCy_sm SpaCy_md SpaCy_lg     Stanza\n",
      "At      advmod   advmod   advmod       case\n",
      "least   advmod   advmod   advmod       nmod\n",
      "two     nummod   nummod   nummod     nummod\n",
      "men      nsubj    nsubj    nsubj      nsubj\n",
      "broke     ROOT     ROOT     ROOT       root\n",
      "in         prt      prt      prt     advmod\n",
      "and         cc       cc       cc         cc\n",
      "stole     conj     conj     conj       conj\n",
      "my        poss     poss     poss  nmod:poss\n",
      "TV        dobj     dobj     dobj        obj\n",
      ".        punct    punct    punct      punct\n",
      "length =  11\n",
      "\n",
      "\n",
      "sentence 2\n",
      "          SpaCy_sm  SpaCy_md  SpaCy_lg     Stanza\n",
      "It           nsubj     nsubj     nsubj      nsubj\n",
      "was           ROOT      ROOT      ROOT        cop\n",
      "my            poss      poss      poss  nmod:poss\n",
      "aunt          nmod      poss      poss  nmod:poss\n",
      "’s           punct      case      case       case\n",
      "car           attr      attr      attr       root\n",
      "which         dobj      dobj      dobj        obj\n",
      "we           nsubj     nsubj     nsubj      nsubj\n",
      "sold         relcl     relcl     relcl  acl:relcl\n",
      "at            prep      prep      prep       case\n",
      "auction       pobj      pobj      pobj        obl\n",
      "last          amod      amod      amod       amod\n",
      "year      npadvmod  npadvmod  npadvmod   obl:tmod\n",
      "in            prep      prep      prep       case\n",
      "February      pobj      pobj      pobj        obl\n",
      ".            punct     punct     punct      punct\n",
      "length =  16\n",
      "\n",
      "\n",
      "sentence 3\n",
      "          SpaCy_sm   SpaCy_md   SpaCy_lg      Stanza\n",
      "The            det        det        det         det\n",
      "only          amod       amod       amod        amod\n",
      "rabbit   nsubjpass  nsubjpass  nsubjpass  nsubj:pass\n",
      "that          dobj       dobj       dobj         obj\n",
      "I            nsubj      nsubj      nsubj       nsubj\n",
      "ever        advmod     advmod     advmod      advmod\n",
      "liked        relcl      relcl      relcl   acl:relcl\n",
      "was        auxpass    auxpass    auxpass    aux:pass\n",
      "eaten         ROOT       ROOT       ROOT        root\n",
      "by           agent      agent      agent        case\n",
      "my            poss       poss       poss   nmod:poss\n",
      "parents       pobj       pobj       pobj         obl\n",
      "one         nummod     nummod     nummod      nummod\n",
      "summer    npadvmod   npadvmod   npadvmod    obl:tmod\n",
      ".            punct      punct      punct       punct\n",
      "length =  15\n",
      "\n",
      "\n",
      "sentence 4\n",
      "             SpaCy_sm  SpaCy_md  SpaCy_lg     Stanza\n",
      "Natural          amod      amod      amod       amod\n",
      "disasters       nsubj     nsubj     nsubj      nsubj\n",
      "–               punct     punct     punct      punct\n",
      "storms          appos     appos     appos      appos\n",
      ",               punct     punct     punct      punct\n",
      "flooding         conj      conj      conj       conj\n",
      ",               punct     punct     punct      punct\n",
      "hurricanes       conj      conj      conj       conj\n",
      "–               punct     punct     punct      punct\n",
      "occur            ROOT      ROOT      ROOT       root\n",
      "infrequently   advmod    advmod    advmod     advmod\n",
      "but                cc        cc        cc         cc\n",
      "cause            conj      conj      conj       conj\n",
      "devastation      dobj      dobj      dobj        obj\n",
      "that            nsubj     nsubj     nsubj      nsubj\n",
      "strains         relcl     relcl     relcl  acl:relcl\n",
      "resources        dobj      dobj      dobj        obj\n",
      "to               prep      prep      prep       case\n",
      "breaking         amod  compound  compound   compound\n",
      "point            pobj      pobj      pobj       nmod\n",
      ".               punct     punct     punct      punct\n",
      "length =  21\n",
      "\n",
      "\n",
      "sentence 5\n",
      "            SpaCy_sm  SpaCy_md  SpaCy_lg  Stanza\n",
      "It             nsubj     nsubj     nsubj   nsubj\n",
      "wo               aux       aux       aux     aux\n",
      "n’t              neg       neg       neg  advmod\n",
      "rain            ROOT      ROOT      ROOT    root\n",
      "but               cc        cc        cc      cc\n",
      "there           expl      expl      expl    expl\n",
      "might            aux       aux       aux     aux\n",
      "be              ROOT      conj      conj    conj\n",
      "snow            attr      attr      attr   nsubj\n",
      "on              prep      prep      prep    case\n",
      "high            amod      amod      amod    amod\n",
      "ground          pobj      pobj      pobj    nmod\n",
      "if              mark      mark      mark    mark\n",
      "the              det       det       det     det\n",
      "temperature    nsubj     nsubj     nsubj   nsubj\n",
      "stays          advcl     advcl     advcl   advcl\n",
      "about           prep    advmod    advmod    case\n",
      "the              det       det       det     det\n",
      "same            pobj  npadvmod  npadvmod     obl\n",
      "over            prep      prep      prep    case\n",
      "the              det       det       det     det\n",
      "next            amod      amod      amod    amod\n",
      "24            nummod    nummod    nummod  nummod\n",
      "hours           pobj      pobj      pobj     obl\n",
      ".              punct     punct     punct   punct\n",
      "length =  25\n",
      "\n",
      "\n",
      "sentence 6\n",
      "                SpaCy_sm   SpaCy_md   SpaCy_lg     Stanza\n",
      "English            nsubj      nsubj      nsubj      nsubj\n",
      "also              advmod     advmod     advmod     advmod\n",
      "has                ccomp       ROOT       ROOT       root\n",
      "many                amod       amod       amod       amod\n",
      "words               dobj       dobj       dobj        obj\n",
      "of                  prep       prep       prep       case\n",
      "more              advmod       amod     advmod       amod\n",
      "or                    cc         cc         cc         cc\n",
      "less                conj       conj       conj     advmod\n",
      "unique              amod       conj       amod       conj\n",
      "function            pobj       pobj       pobj       nmod\n",
      ",                  punct      punct      punct      punct\n",
      "including           prep       prep       prep       case\n",
      "interjections       pobj       pobj       pobj       nmod\n",
      "(                  punct      punct      punct      punct\n",
      "oh                  intj       intj       prep  discourse\n",
      ",                  punct      punct      punct      punct\n",
      "ah                  intj       intj       intj  discourse\n",
      ")                  punct      punct      punct      punct\n",
      ",                  punct      punct      punct      punct\n",
      "negatives           conj      appos       conj       conj\n",
      "(                  punct      punct      punct      punct\n",
      "no                  intj       intj       intj  discourse\n",
      ",                  punct      punct      punct      punct\n",
      "not                  neg      appos       intj  parataxis\n",
      ")                  punct      punct      punct      punct\n",
      ",                  punct      punct      punct      punct\n",
      "politeness      compound   compound   compound   compound\n",
      "markers             conj      appos       conj  parataxis\n",
      "(                  punct      punct      punct      punct\n",
      "please              intj       intj       intj  discourse\n",
      ",                  punct      punct      punct      punct\n",
      "thank          parataxis  parataxis  parataxis  parataxis\n",
      "you                 dobj       dobj       dobj        obj\n",
      ")                  punct      punct      punct      punct\n",
      ",                  punct      punct      punct      punct\n",
      "and                   cc         cc         cc         cc\n",
      "the                  det        det        det        det\n",
      "existential         conj       conj       conj      nsubj\n",
      "‘                  punct      punct      punct      punct\n",
      "there             advmod     advmod     advmod       conj\n",
      "’                  punct      punct      punct      punct\n",
      "(                  punct      punct      punct      punct\n",
      "there               expl       expl       expl       expl\n",
      "are                 ROOT       ROOT       ROOT  parataxis\n",
      "horses              attr       attr       attr      nsubj\n",
      "but                   cc         cc         cc         cc\n",
      "not                  neg        neg        neg     advmod\n",
      "unicorns            conj       conj       conj       conj\n",
      ")                  punct      punct      punct      punct\n",
      "among               prep       prep       prep       case\n",
      "others              pobj       pobj       pobj        obl\n",
      ".                  punct      punct      punct      punct\n",
      "length =  53\n",
      "\n",
      "\n",
      "sentence 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            SpaCy_sm   SpaCy_md   SpaCy_lg      Stanza\n",
      "The              det        det        det         det\n",
      "Penn        compound   compound   compound    compound\n",
      "Treebank    compound   compound   compound    compound\n",
      "tagset     nsubjpass  nsubjpass  nsubjpass  nsubj:pass\n",
      "was          auxpass    auxpass    auxpass    aux:pass\n",
      "culled          ROOT       ROOT       ROOT        root\n",
      "from            prep       prep       prep        case\n",
      "the              det        det        det         det\n",
      "original        amod       amod       amod        amod\n",
      "87tag       compound   compound   compound    compound\n",
      "tagset          pobj       pobj       pobj         obl\n",
      "for             prep       prep       prep        case\n",
      "the              det        det        det         det\n",
      "Brown       compound   compound   compound    compound\n",
      "Corpus          pobj       pobj       pobj        nmod\n",
      ".              punct      punct      punct       punct\n",
      "For             prep       prep       prep        case\n",
      "example         pobj       pobj       pobj         obl\n",
      "the              det        det        det         det\n",
      "original        amod       amod       amod        amod\n",
      "Brown           nmod       nmod       nmod       nsubj\n",
      "and               cc         cc         cc          cc\n",
      "C5              conj       conj       conj    compound\n",
      "tagsets        nsubj      nsubj      nsubj        conj\n",
      "include         ROOT       ROOT       ROOT        root\n",
      "a                det        det        det         det\n",
      "separate        amod       amod       amod        amod\n",
      "tag             dobj       dobj       dobj         obj\n",
      "for             prep       prep       prep        case\n",
      "each            pobj       pobj       pobj        nmod\n",
      "of              prep       prep       prep        case\n",
      "the              det        det        det         det\n",
      "different       amod       amod       amod        amod\n",
      "forms           pobj       pobj       pobj        nmod\n",
      "of              prep       prep       prep        case\n",
      "the              det        det        det         det\n",
      "verbs           pobj       pobj       pobj        nmod\n",
      "do              dobj       conj       prep   acl:relcl\n",
      "(              punct      punct      punct       punct\n",
      "e.g.        compound     advmod     advmod      advmod\n",
      "C5          compound   compound   compound    compound\n",
      "tag         compound   compound   compound    compound\n",
      "VDD             dobj      appos      appos         obj\n",
      "for             prep       prep       prep        mark\n",
      "did             pobj       pobj       pobj        nmod\n",
      "and               cc         cc         cc          cc\n",
      "VDG             conj   compound   compound    compound\n",
      "tag             dobj       conj       conj        conj\n",
      "for             prep       prep       prep        mark\n",
      "doing           pobj      pcomp       pobj         acl\n",
      ")              punct      punct      punct       punct\n",
      ",              punct      punct      punct       punct\n",
      "be              ROOT       conj       conj   parataxis\n",
      "and               cc         cc         cc          cc\n",
      "have            conj       conj       conj        conj\n",
      ".              punct      punct      punct       punct\n",
      "length =  56\n",
      "\n",
      "\n",
      "sentence 8\n",
      "             SpaCy_sm  SpaCy_md  SpaCy_lg      Stanza\n",
      "Thus           advmod    advmod    advmod      advmod\n",
      "the               det       det       det         det\n",
      "EM           npadvmod  npadvmod  npadvmod   obl:npmod\n",
      "-               punct     punct     punct       punct\n",
      "trained          amod      amod      amod        amod\n",
      "“               punct     punct     punct       punct\n",
      "pure             amod      amod      amod        amod\n",
      "HMM              nmod       det      nmod       appos\n",
      "”               punct     punct     punct       punct\n",
      "tagger      nsubjpass     nsubj     nsubj  nsubj:pass\n",
      "is            auxpass   auxpass      ROOT    aux:pass\n",
      "probably       advmod    advmod    advmod      advmod\n",
      "best           advmod    advmod    advmod      advmod\n",
      "suited           ROOT      ROOT     acomp        root\n",
      "to               prep      prep      prep        case\n",
      "cases            pobj      pobj      pobj         obl\n",
      "where          advmod    advmod    advmod      advmod\n",
      "no                det       det       det         det\n",
      "training     compound  compound  compound    compound\n",
      "data            nsubj     nsubj     nsubj       nsubj\n",
      "is              relcl     relcl     relcl         cop\n",
      "available       acomp     acomp     acomp   acl:relcl\n",
      ",               punct     punct     punct       punct\n",
      "for              prep      prep      prep        case\n",
      "example          pobj      pobj      pobj         obl\n",
      ",               punct     punct     punct       punct\n",
      "when           advmod    advmod    advmod        mark\n",
      "tagging         advcl     advcl     advcl       advcl\n",
      "languages        dobj      dobj      dobj         obj\n",
      "for              prep      prep      prep        case\n",
      "which            pobj      pobj      pobj         obl\n",
      "no                det       det       det         det\n",
      "data            nsubj     nsubj     nsubj  nsubj:pass\n",
      "was           auxpass     relcl     relcl    aux:pass\n",
      "previously     advmod    advmod    advmod      advmod\n",
      "hand         npadvmod  npadvmod  npadvmod   obl:npmod\n",
      "-               punct     punct     punct       punct\n",
      "tagged           amod     acomp     acomp   acl:relcl\n",
      ".               punct     punct     punct       punct\n",
      "length =  39\n",
      "\n",
      "\n",
      "sentence 9\n",
      "               SpaCy_sm  SpaCy_md  SpaCy_lg    Stanza\n",
      "Skill             nsubj     nsubj     nsubj     nsubj\n",
      "without            prep      prep      prep      case\n",
      "imagination        pobj      pobj      pobj      nmod\n",
      "is                 ROOT      ROOT      ROOT       cop\n",
      "craftsmanship     acomp     acomp      attr      root\n",
      "and                  cc        cc        cc        cc\n",
      "gives              conj      conj      conj      conj\n",
      "us               dative    dative    dative      iobj\n",
      "many               amod      amod      amod      amod\n",
      "useful             amod      amod      amod      amod\n",
      "objects            dobj      dobj      dobj       obj\n",
      "such               amod      amod      amod      case\n",
      "as                 prep      prep      prep     fixed\n",
      "wickerwork     compound  compound  compound      amod\n",
      "picnic         compound  compound  compound  compound\n",
      "baskets            pobj      pobj      pobj      nmod\n",
      ".                 punct     punct     punct     punct\n",
      "Imagination       nsubj     nsubj     nsubj     nsubj\n",
      "without            prep      prep      prep      case\n",
      "skill              pobj      pobj      pobj      nmod\n",
      "gives              ROOT      ROOT      ROOT      root\n",
      "us               dative    dative    dative      iobj\n",
      "modern             amod      amod      amod      amod\n",
      "art                dobj      dobj      dobj       obj\n",
      ".                 punct     punct     punct     punct\n",
      "length =  25\n",
      "\n",
      "\n",
      "sentence 10\n",
      "             SpaCy_sm  SpaCy_md  SpaCy_lg      Stanza\n",
      "But                cc        cc        cc          cc\n",
      "far            advmod    advmod    advmod      advmod\n",
      "fewer            amod      amod      amod        amod\n",
      "people          nsubj     nsubj     nsubj       nsubj\n",
      "fully          advmod    advmod    advmod      advmod\n",
      "understand      ccomp     ccomp     ccomp        root\n",
      "how            advmod    advmod    advmod      advmod\n",
      "the               det       det       det         det\n",
      "Media        compound  compound  compound    compound\n",
      "Lab             nsubj     nsubj     nsubj       nsubj\n",
      "operates        ccomp     ccomp     ccomp       ccomp\n",
      ",               punct     punct     punct       punct\n",
      "fits            ccomp      conj      conj        conj\n",
      "into             prep      prep      prep        case\n",
      "MIT              pobj      pobj      pobj         obl\n",
      ",               punct     punct     punct       punct\n",
      "and                cc        cc        cc          cc\n",
      "encourages       conj      conj      conj        conj\n",
      "such           predet    predet    predet  det:predet\n",
      "a                 det       det       det         det\n",
      "creative         amod      amod      amod        amod\n",
      "environment      dobj      dobj      dobj         obj\n",
      ";               punct     punct     punct       punct\n",
      "about        quantmod    advmod  quantmod      advmod\n",
      "half            nsubj     nsubj     nsubj         obj\n",
      "of               prep      prep      prep        case\n",
      "the               det       det       det         det\n",
      "anniversary  compound  compound  compound        amod\n",
      "celebration      pobj      poss      poss   nmod:poss\n",
      "’s              punct      case      case        case\n",
      "program         appos      pobj      pobj        nmod\n",
      "focused          ROOT      ROOT      ROOT         acl\n",
      "on               prep      prep      prep        mark\n",
      "simply         advmod    advmod    advmod      advmod\n",
      "defining        pcomp     pcomp     pcomp       advcl\n",
      "what             attr      attr      attr       ccomp\n",
      "the               det       det       det         det\n",
      "Media        compound  compound  compound    compound\n",
      "Lab             nsubj     nsubj     nsubj       nsubj\n",
      "is              ccomp     ccomp     ccomp         cop\n",
      ".               punct     punct     punct       punct\n",
      "length =  41\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Implement the method comparison_dep\n",
    "for i in range(len(texts)):\n",
    "    comparison_dep(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make comparison tables of \"Head\" of SpaCy and Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to make comparison tables of \"Head\" of SpaCy and Stanza\n",
    "def comparison_head(number):\n",
    "    text = texts[number]\n",
    "    print('sentence' , number)    \n",
    "\n",
    "    spacy = []\n",
    "    spacy_index = []\n",
    "    spacy_pos = []\n",
    "    spacy_tag =[]\n",
    "    spacy_dep = []\n",
    "    spacy_head = []\n",
    "\n",
    "    doc_spacy = nlp_spacy_sm(text)\n",
    "    for d in doc_spacy:\n",
    "        spacy_index.append((d.text))\n",
    "        spacy_pos.append((d.pos_))\n",
    "        spacy_tag.append((d.tag_))\n",
    "        spacy_dep.append((d.dep_))\n",
    "        spacy_head.append((d.head))\n",
    "\n",
    "    spacy.append(spacy_pos)\n",
    "    spacy.append(spacy_tag)\n",
    "    spacy.append(spacy_dep)\n",
    "    spacy.append(spacy_head)\n",
    "\n",
    "    df_spacy_sm = pd.DataFrame(spacy,\n",
    "                      index=['pos', 'tag', 'dep', 'head'],\n",
    "                      columns=spacy_index)\n",
    "    df_spacy_sm = df_spacy_sm.T\n",
    "\n",
    "    spacy = []\n",
    "    spacy_index = []\n",
    "    spacy_pos = []\n",
    "    spacy_tag =[]\n",
    "    spacy_dep = []\n",
    "    spacy_head = []\n",
    "\n",
    "    doc_spacy = nlp_spacy_md(text)\n",
    "    for d in doc_spacy:\n",
    "        spacy_index.append((d.text))\n",
    "        spacy_pos.append((d.pos_))\n",
    "        spacy_tag.append((d.tag_))\n",
    "        spacy_dep.append((d.dep_))\n",
    "        spacy_head.append((d.head))\n",
    "\n",
    "    spacy.append(spacy_pos)\n",
    "    spacy.append(spacy_tag)\n",
    "    spacy.append(spacy_dep)\n",
    "    spacy.append(spacy_head)\n",
    "\n",
    "    df_spacy_md = pd.DataFrame(spacy,\n",
    "                      index=['pos', 'tag', 'dep', 'head'],\n",
    "                      columns=spacy_index)\n",
    "    df_spacy_md = df_spacy_md.T\n",
    "\n",
    "    spacy = []\n",
    "    spacy_index = []\n",
    "    spacy_pos = []\n",
    "    spacy_tag =[]\n",
    "    spacy_dep = []\n",
    "    spacy_head = []\n",
    "\n",
    "    doc_spacy = nlp_spacy_lg(text)\n",
    "    for d in doc_spacy:\n",
    "        spacy_index.append((d.text))\n",
    "        spacy_pos.append((d.pos_))\n",
    "        spacy_tag.append((d.tag_))\n",
    "        spacy_dep.append((d.dep_))\n",
    "        spacy_head.append((d.head))\n",
    "\n",
    "    spacy.append(spacy_pos)\n",
    "    spacy.append(spacy_tag)\n",
    "    spacy.append(spacy_dep)\n",
    "    spacy.append(spacy_head)\n",
    "\n",
    "    df_spacy_lg = pd.DataFrame(spacy,\n",
    "                      index=['pos', 'tag', 'dep', 'head'],\n",
    "                      columns=spacy_index)\n",
    "    df_spacy_lg = df_spacy_lg.T\n",
    "\n",
    "    stanza = []\n",
    "    stanza_index = []\n",
    "    stanza_pos = []\n",
    "    stanza_tag =[]\n",
    "    stanza_dep = []\n",
    "    stanza_head = []\n",
    "\n",
    "    doc_stanza = nlp_stanza(text)\n",
    "    sentence_number = len(doc_stanza.sentences)\n",
    "    \n",
    "    for i in range(sentence_number):\n",
    "        sentence = doc_stanza.sentences[i]\n",
    "        for token in sentence.tokens:\n",
    "            stanza_index.append(token.words[0].text)\n",
    "            stanza_pos.append(token.words[0].upos)\n",
    "            stanza_tag.append(token.words[0].xpos)\n",
    "            stanza_dep.append(token.words[0].deprel)\n",
    "            stanza_head.append(sentence.tokens[token.words[0].head-1].words[0].text)\n",
    "    \n",
    "    stanza.append(stanza_pos)\n",
    "    stanza.append(stanza_tag)\n",
    "    stanza.append(stanza_dep)\n",
    "    stanza.append(stanza_head)\n",
    "\n",
    "    df_stanza = pd.DataFrame(stanza,\n",
    "                      index=['pos', 'tag', 'dep', 'head'],\n",
    "                      columns=stanza_index)\n",
    "    df_stanza = df_stanza.T\n",
    "    \n",
    "    df_head = pd.concat([df_spacy_sm['head'], df_spacy_md['head'],df_spacy_lg['head'], df_stanza['head']], axis=1)\n",
    "    df_head.columns = ['SpaCy_sm', 'SpaCy_md', 'SpaCy_lg', 'Stanza']\n",
    "    print(df_head)\n",
    "    print('length = ',len(df_head))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence 0\n",
      "      SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "The        car      car      car    car\n",
      "old        car      car      car    car\n",
      "car      broke    broke    broke  broke\n",
      "broke    broke    broke    broke      .\n",
      "down     broke    broke    broke  broke\n",
      "in       broke    broke    broke   park\n",
      "the       park     park     park   park\n",
      "car       park     park     park   park\n",
      "park        in       in       in  broke\n",
      ".        broke    broke    broke  broke\n",
      "length =  10\n",
      "\n",
      "\n",
      "sentence 1\n",
      "      SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "At       least    least    least  least\n",
      "least      two      two      two    two\n",
      "two        men      men      men    men\n",
      "men      broke    broke    broke  broke\n",
      "broke    broke    broke    broke      .\n",
      "in       broke    broke    broke  broke\n",
      "and      broke    broke    broke  stole\n",
      "stole    broke    broke    broke  broke\n",
      "my          TV       TV       TV     TV\n",
      "TV       stole    stole    stole  stole\n",
      ".        broke    broke    broke  broke\n",
      "length =  11\n",
      "\n",
      "\n",
      "sentence 2\n",
      "         SpaCy_sm SpaCy_md SpaCy_lg    Stanza\n",
      "It            was      was      was       car\n",
      "was           was      was      was       car\n",
      "my           aunt     aunt     aunt      aunt\n",
      "aunt          car      car      car       car\n",
      "’s           aunt     aunt     aunt      aunt\n",
      "car           was      was      was         .\n",
      "which        sold     sold     sold      sold\n",
      "we           sold     sold     sold      sold\n",
      "sold          car      car      car       car\n",
      "at           sold     sold     sold   auction\n",
      "auction        at       at       at      sold\n",
      "last         year     year     year      year\n",
      "year         sold     sold     sold      sold\n",
      "in           sold     sold     sold  February\n",
      "February       in       in       in      sold\n",
      ".             was      was      was       car\n",
      "length =  16\n",
      "\n",
      "\n",
      "sentence 3\n",
      "        SpaCy_sm SpaCy_md SpaCy_lg   Stanza\n",
      "The       rabbit   rabbit   rabbit   rabbit\n",
      "only      rabbit   rabbit   rabbit   rabbit\n",
      "rabbit     eaten    eaten    eaten    eaten\n",
      "that       liked    liked    liked    liked\n",
      "I          liked    liked    liked    liked\n",
      "ever       liked    liked    liked    liked\n",
      "liked     rabbit   rabbit   rabbit   rabbit\n",
      "was        eaten    eaten    eaten    eaten\n",
      "eaten      eaten    eaten    eaten        .\n",
      "by         eaten    eaten    eaten  parents\n",
      "my       parents  parents  parents  parents\n",
      "parents       by       by       by    eaten\n",
      "one       summer   summer   summer   summer\n",
      "summer     eaten    eaten    eaten    eaten\n",
      ".          eaten    eaten    eaten    eaten\n",
      "length =  15\n",
      "\n",
      "\n",
      "sentence 4\n",
      "                 SpaCy_sm     SpaCy_md     SpaCy_lg       Stanza\n",
      "Natural         disasters    disasters    disasters    disasters\n",
      "disasters           occur        occur        occur        occur\n",
      "–               disasters    disasters    disasters    disasters\n",
      "storms          disasters    disasters    disasters    disasters\n",
      ",                  storms       storms       storms     flooding\n",
      "flooding           storms       storms       storms       storms\n",
      ",                flooding     flooding     flooding   hurricanes\n",
      "hurricanes       flooding     flooding     flooding       storms\n",
      "–               disasters    disasters    disasters    disasters\n",
      "occur               occur        occur        occur            .\n",
      "infrequently        occur        occur        occur        occur\n",
      "but                 occur        occur        occur        cause\n",
      "cause               occur        occur        occur        occur\n",
      "devastation         cause        cause        cause        cause\n",
      "that              strains      strains      strains      strains\n",
      "strains       devastation  devastation  devastation  devastation\n",
      "resources         strains      strains      strains      strains\n",
      "to                strains      strains      strains        point\n",
      "breaking            point        point        point        point\n",
      "point                  to           to           to    resources\n",
      ".                   occur        occur        occur        occur\n",
      "length =  21\n",
      "\n",
      "\n",
      "sentence 5\n",
      "                SpaCy_sm     SpaCy_md     SpaCy_lg       Stanza\n",
      "It                  rain         rain         rain         rain\n",
      "wo                  rain         rain         rain         rain\n",
      "n’t                 rain         rain         rain         rain\n",
      "rain                rain         rain         rain            .\n",
      "but                   be         rain         rain           be\n",
      "there                 be           be           be           be\n",
      "might                 be           be           be           be\n",
      "be                    be         rain         rain         rain\n",
      "snow                  be           be           be           be\n",
      "on                  snow         snow         snow       ground\n",
      "high              ground       ground       ground       ground\n",
      "ground                on           on           on         snow\n",
      "if                 stays        stays        stays        stays\n",
      "the          temperature  temperature  temperature  temperature\n",
      "temperature        stays        stays        stays        stays\n",
      "stays                 be           be           be           be\n",
      "about              stays         same         same         same\n",
      "the                 same         same         same         same\n",
      "same               about        stays        stays        stays\n",
      "over               stays        stays        stays        hours\n",
      "the                hours        hours        hours        hours\n",
      "next               hours        hours        hours        hours\n",
      "24                 hours        hours        hours        hours\n",
      "hours               over         over         over        stays\n",
      ".                     be           be           be         rain\n",
      "length =  25\n",
      "\n",
      "\n",
      "sentence 6\n",
      "                    SpaCy_sm       SpaCy_md       SpaCy_lg         Stanza\n",
      "English                  has            has            has            has\n",
      "also                     has            has            has            has\n",
      "has                      are            has            has              .\n",
      "many                   words          words          words          words\n",
      "words                    has            has            has            has\n",
      "of                     words          words          words       function\n",
      "more                  unique       function         unique       function\n",
      "or                      more           more           more         unique\n",
      "less                    more           more           more         unique\n",
      "unique              function           more       function           more\n",
      "function                  of             of             of          words\n",
      ",                   function       function       function       function\n",
      "including           function       function       function  interjections\n",
      "interjections      including      including      including       function\n",
      "(              interjections  interjections  interjections             ah\n",
      "oh             interjections  interjections  interjections             ah\n",
      ",                         oh             oh             oh             ah\n",
      "ah                        oh             oh             oh      negatives\n",
      ")              interjections             oh             oh             ah\n",
      ",              interjections  interjections  interjections      negatives\n",
      "negatives      interjections  interjections  interjections          words\n",
      "(                  negatives             no      negatives            not\n",
      "no                 negatives            not            not            not\n",
      ",                  negatives             no             no            not\n",
      "not                negatives      negatives      negatives      negatives\n",
      ")                  negatives       function      negatives            not\n",
      ",              interjections            has  interjections        markers\n",
      "politeness           markers        markers        markers        markers\n",
      "markers        interjections        English  interjections      negatives\n",
      "(                      thank          thank          thank          thank\n",
      "please                 thank          thank          thank          thank\n",
      ",                      thank          thank          thank          thank\n",
      "thank                markers        markers        markers        markers\n",
      "you                    thank          thank          thank          thank\n",
      ")                      thank          thank          thank          thank\n",
      ",                      thank          thank        markers          there\n",
      "and                  markers        markers        markers          there\n",
      "the              existential    existential    existential    existential\n",
      "existential          markers        markers        markers          there\n",
      "‘                existential    existential    existential          there\n",
      "there            existential    existential    existential          thank\n",
      "’                existential    existential    existential          there\n",
      "(                        are            are            are            are\n",
      "there                    are            are            are            are\n",
      "are                      are            are            are          there\n",
      "horses                   are            are            are            are\n",
      "but                   horses         horses         horses       unicorns\n",
      "not                 unicorns       unicorns       unicorns       unicorns\n",
      "unicorns              horses         horses         horses         horses\n",
      ")                     horses         horses         horses            are\n",
      "among                 horses            are            are         others\n",
      "others                 among          among          among            are\n",
      ".                        are            are            are            has\n",
      "length =  53\n",
      "\n",
      "\n",
      "sentence 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           SpaCy_sm  SpaCy_md  SpaCy_lg   Stanza\n",
      "The          tagset    tagset    tagset   tagset\n",
      "Penn       Treebank  Treebank  Treebank   tagset\n",
      "Treebank     tagset    tagset    tagset   tagset\n",
      "tagset       culled    culled    culled   culled\n",
      "was          culled    culled    culled   culled\n",
      "culled       culled    culled    culled        .\n",
      "from         culled    culled    culled   tagset\n",
      "the          tagset    tagset    tagset   tagset\n",
      "original     tagset    tagset     87tag   tagset\n",
      "87tag        tagset    tagset    tagset   tagset\n",
      "tagset         from      from      from   culled\n",
      "for          tagset    tagset    tagset   Corpus\n",
      "the          Corpus    Corpus    Corpus   Corpus\n",
      "Brown        Corpus    Corpus    Corpus   Corpus\n",
      "Corpus          for       for       for   tagset\n",
      ".            culled    culled    culled   culled\n",
      "For         include   include   include  example\n",
      "example         For       For       For  include\n",
      "the         tagsets   tagsets   tagsets    Brown\n",
      "original    tagsets   tagsets   tagsets    Brown\n",
      "Brown       tagsets   tagsets   tagsets  include\n",
      "and           Brown     Brown     Brown  tagsets\n",
      "C5            Brown     Brown     Brown  tagsets\n",
      "tagsets     include   include   include    Brown\n",
      "include     include   include   include        .\n",
      "a               tag       tag       tag      tag\n",
      "separate        tag       tag       tag      tag\n",
      "tag         include   include   include  include\n",
      "for             tag       tag       tag     each\n",
      "each            for       for       for      tag\n",
      "of             each      each      each    forms\n",
      "the           forms     forms     forms    forms\n",
      "different     forms     forms     forms    forms\n",
      "forms            of        of        of     each\n",
      "of            forms     forms     forms    verbs\n",
      "the           verbs     verbs     verbs    verbs\n",
      "verbs            of        of        of    forms\n",
      "do          include   include       tag      tag\n",
      "(               VDD        do        do      VDD\n",
      "e.g.            VDD       VDD       VDD      VDD\n",
      "C5              VDD       VDD       VDD      VDD\n",
      "tag             VDD       VDD       VDD      VDD\n",
      "VDD              do        do        do       do\n",
      "for             VDD       VDD       VDD      did\n",
      "did             for       for       for      VDD\n",
      "and             did       VDD       VDD      tag\n",
      "VDG             did       tag       tag      tag\n",
      "tag             VDG       VDD       VDD      VDD\n",
      "for             tag       tag       tag    doing\n",
      "doing           for       for       for      tag\n",
      ")               VDD       tag        do      VDD\n",
      ",                do        do   include       be\n",
      "be               be        do   include  include\n",
      "and              be        be        be     have\n",
      "have             be        be        be       be\n",
      ".                be   include   include  include\n",
      "length =  56\n",
      "\n",
      "\n",
      "sentence 8\n",
      "             SpaCy_sm   SpaCy_md   SpaCy_lg     Stanza\n",
      "Thus           suited     suited         is     suited\n",
      "the            tagger     tagger     tagger     tagger\n",
      "EM            trained    trained    trained    trained\n",
      "-             trained    trained    trained    trained\n",
      "trained        tagger     tagger     tagger     tagger\n",
      "“              tagger     tagger     tagger        HMM\n",
      "pure              HMM        HMM     tagger     tagger\n",
      "HMM            tagger          “     tagger     tagger\n",
      "”              tagger     tagger     tagger        HMM\n",
      "tagger         suited         is         is     suited\n",
      "is             suited     suited         is     suited\n",
      "probably       suited     suited         is     suited\n",
      "best           suited     suited     suited     suited\n",
      "suited         suited     suited         is          .\n",
      "to             suited     suited     suited      cases\n",
      "cases              to         to         to     suited\n",
      "where              is         is         is  available\n",
      "no               data       data       data       data\n",
      "training         data       data       data       data\n",
      "data               is         is         is  available\n",
      "is              cases      cases      cases  available\n",
      "available          is         is         is      cases\n",
      ",              suited         is         is  available\n",
      "for            suited         is         is    example\n",
      "example           for        for        for  available\n",
      ",              suited         is         is  available\n",
      "when          tagging    tagging    tagging    tagging\n",
      "tagging        suited         is         is  available\n",
      "languages     tagging    tagging    tagging    tagging\n",
      "for               was        was        was      which\n",
      "which             for        for        for     tagged\n",
      "no               data       data       data       data\n",
      "data              was        was        was     tagged\n",
      "was            tagged  languages  languages     tagged\n",
      "previously     tagged        was        was     tagged\n",
      "hand           tagged     tagged     tagged     tagged\n",
      "-              tagged     tagged     tagged     tagged\n",
      "tagged      languages        was        was  languages\n",
      ".              suited     suited         is     suited\n",
      "length =  39\n",
      "\n",
      "\n",
      "sentence 9\n",
      "                  SpaCy_sm     SpaCy_md     SpaCy_lg         Stanza\n",
      "Skill                   is           is           is  craftsmanship\n",
      "without              Skill        Skill        Skill    imagination\n",
      "imagination        without      without      without          Skill\n",
      "is                      is           is           is  craftsmanship\n",
      "craftsmanship           is           is           is              .\n",
      "and                     is           is           is          gives\n",
      "gives                   is           is           is  craftsmanship\n",
      "us                   gives        gives        gives          gives\n",
      "many               objects      objects      objects        objects\n",
      "useful             objects      objects      objects        objects\n",
      "objects              gives        gives        gives          gives\n",
      "such                    as           as           as        baskets\n",
      "as                 objects      objects      objects           such\n",
      "wickerwork          picnic      baskets      baskets        baskets\n",
      "picnic             baskets      baskets      baskets        baskets\n",
      "baskets                 as           as           as        objects\n",
      ".                       is           is           is  craftsmanship\n",
      "Imagination          gives        gives        gives          gives\n",
      "without        Imagination  Imagination  Imagination          skill\n",
      "skill              without      without      without    Imagination\n",
      "gives                gives        gives        gives              .\n",
      "us                   gives        gives        gives          gives\n",
      "modern                 art          art          art            art\n",
      "art                  gives        gives        gives          gives\n",
      ".                    gives        gives        gives          gives\n",
      "length =  25\n",
      "\n",
      "\n",
      "sentence 10\n",
      "                SpaCy_sm     SpaCy_md     SpaCy_lg       Stanza\n",
      "But           understand   understand   understand   encourages\n",
      "far                fewer        fewer        fewer        fewer\n",
      "fewer             people       people       people       people\n",
      "people        understand   understand   understand   understand\n",
      "fully         understand   understand   understand   understand\n",
      "understand       focused      focused      focused            .\n",
      "how             operates     operates     operates     operates\n",
      "the                  Lab          Lab          Lab          Lab\n",
      "Media                Lab          Lab          Lab          Lab\n",
      "Lab             operates     operates     operates     operates\n",
      "operates      understand   understand   understand   understand\n",
      ",               operates   understand     operates         fits\n",
      "fits          understand   understand   understand     operates\n",
      "into                fits         fits         fits          MIT\n",
      "MIT                 into         into         into         fits\n",
      ",             understand         fits         fits   encourages\n",
      "and           understand         fits         fits   encourages\n",
      "encourages    understand         fits         fits     operates\n",
      "such         environment  environment  environment  environment\n",
      "a            environment  environment  environment  environment\n",
      "creative     environment  environment  environment  environment\n",
      "environment   encourages   encourages   encourages   encourages\n",
      ";                focused      focused      focused   encourages\n",
      "about               half         half         half         half\n",
      "half             focused      focused      focused   encourages\n",
      "of                  half         half         half      program\n",
      "the          celebration  celebration  celebration  celebration\n",
      "anniversary  celebration  celebration  celebration  celebration\n",
      "celebration           of      program      program      program\n",
      "’s                  half  celebration  celebration  celebration\n",
      "program             half           of           of         half\n",
      "focused          focused      focused      focused      program\n",
      "on               focused      focused      focused     defining\n",
      "simply          defining     defining     defining     defining\n",
      "defining              on           on           on      focused\n",
      "what                  is           is           is     defining\n",
      "the                  Lab          Lab          Lab          Lab\n",
      "Media                Lab          Lab          Lab          Lab\n",
      "Lab                   is           is           is         what\n",
      "is              defining     defining     defining         what\n",
      ".                focused      focused      focused   understand\n",
      "length =  41\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Implement the method comparison_head(number):\n",
    "for i in range(len(texts)):\n",
    "    comparison_head(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make comparison tables of \"POS\" of SpaCy and Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to make comparison tables of \"POS\" of SpaCy and Stanza\n",
    "def comparison_pos(number):\n",
    "    text = texts[number]\n",
    "    sentence_number = sentence_numbers[number]\n",
    "    print('sentence' , sentence_number)    \n",
    "\n",
    "    spacy = []\n",
    "    spacy_index = []\n",
    "    spacy_pos = []\n",
    "    spacy_tag =[]\n",
    "    spacy_dep = []\n",
    "    spacy_head = []\n",
    "\n",
    "    doc_spacy = nlp_spacy_sm(text)\n",
    "    for d in doc_spacy:\n",
    "        spacy_index.append((d.text))\n",
    "        spacy_pos.append((d.pos_))\n",
    "        spacy_tag.append((d.tag_))\n",
    "        spacy_dep.append((d.dep_))\n",
    "        spacy_head.append((d.head))\n",
    "\n",
    "    spacy.append(spacy_pos)\n",
    "    spacy.append(spacy_tag)\n",
    "    spacy.append(spacy_dep)\n",
    "    spacy.append(spacy_head)\n",
    "\n",
    "    df_spacy_sm = pd.DataFrame(spacy,\n",
    "                      index=['pos', 'tag', 'dep', 'head'],\n",
    "                      columns=spacy_index)\n",
    "    df_spacy_sm = df_spacy_sm.T\n",
    "\n",
    "    spacy = []\n",
    "    spacy_index = []\n",
    "    spacy_pos = []\n",
    "    spacy_tag =[]\n",
    "    spacy_dep = []\n",
    "    spacy_head = []\n",
    "\n",
    "    doc_spacy = nlp_spacy_md(text)\n",
    "    for d in doc_spacy:\n",
    "        spacy_index.append((d.text))\n",
    "        spacy_pos.append((d.pos_))\n",
    "        spacy_tag.append((d.tag_))\n",
    "        spacy_dep.append((d.dep_))\n",
    "        spacy_head.append((d.head))\n",
    "\n",
    "    spacy.append(spacy_pos)\n",
    "    spacy.append(spacy_tag)\n",
    "    spacy.append(spacy_dep)\n",
    "    spacy.append(spacy_head)\n",
    "\n",
    "    df_spacy_md = pd.DataFrame(spacy,\n",
    "                      index=['pos', 'tag', 'dep', 'head'],\n",
    "                      columns=spacy_index)\n",
    "    df_spacy_md = df_spacy_md.T\n",
    "\n",
    "    spacy = []\n",
    "    spacy_index = []\n",
    "    spacy_pos = []\n",
    "    spacy_tag =[]\n",
    "    spacy_dep = []\n",
    "    spacy_head = []\n",
    "\n",
    "    doc_spacy = nlp_spacy_lg(text)\n",
    "    for d in doc_spacy:\n",
    "        spacy_index.append((d.text))\n",
    "        spacy_pos.append((d.pos_))\n",
    "        spacy_tag.append((d.tag_))\n",
    "        spacy_dep.append((d.dep_))\n",
    "        spacy_head.append((d.head))\n",
    "\n",
    "    spacy.append(spacy_pos)\n",
    "    spacy.append(spacy_tag)\n",
    "    spacy.append(spacy_dep)\n",
    "    spacy.append(spacy_head)\n",
    "\n",
    "    df_spacy_lg = pd.DataFrame(spacy,\n",
    "                      index=['pos', 'tag', 'dep', 'head'],\n",
    "                      columns=spacy_index)\n",
    "    df_spacy_lg = df_spacy_lg.T\n",
    "\n",
    "    stanza = []\n",
    "    stanza_index = []\n",
    "    stanza_pos = []\n",
    "    stanza_tag =[]\n",
    "    stanza_dep = []\n",
    "    stanza_head = []\n",
    "\n",
    "    doc_stanza = nlp_stanza(text)\n",
    "    sentence_number = len(doc_stanza.sentences)\n",
    "    \n",
    "    for i in range(sentence_number):\n",
    "        sentence = doc_stanza.sentences[i]\n",
    "        for token in sentence.tokens:\n",
    "            stanza_index.append(token.words[0].text)\n",
    "            stanza_pos.append(token.words[0].upos)\n",
    "            stanza_tag.append(token.words[0].xpos)\n",
    "            stanza_dep.append(token.words[0].deprel)\n",
    "            stanza_head.append(sentence.tokens[token.words[0].head-1].words[0].text)\n",
    "    \n",
    "    stanza.append(stanza_pos)\n",
    "    stanza.append(stanza_tag)\n",
    "    stanza.append(stanza_dep)\n",
    "    stanza.append(stanza_head)\n",
    "\n",
    "    df_stanza = pd.DataFrame(stanza,\n",
    "                      index=['pos', 'tag', 'dep', 'head'],\n",
    "                      columns=stanza_index)\n",
    "    df_stanza = df_stanza.T\n",
    "    \n",
    "    df_pos = pd.concat([df_spacy_sm['pos'], df_spacy_md['pos'],df_spacy_lg['pos'], df_stanza['pos']], axis=1, join='outer')\n",
    "    df_pos.columns = ['SpaCy_sm', 'SpaCy_md', 'SpaCy_lg', 'Stanza']\n",
    "    print(df_pos)\n",
    "    print('length = ',len(df_pos))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence 1\n",
      "      SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "The        DET      DET      DET    DET\n",
      "old        ADJ      ADJ      ADJ    ADJ\n",
      "car       NOUN     NOUN     NOUN   NOUN\n",
      "broke     VERB     VERB     VERB   VERB\n",
      "down       ADP      ADP      ADP    ADP\n",
      "in         ADP      ADP      ADP    ADP\n",
      "the        DET      DET      DET    DET\n",
      "car       NOUN     NOUN     NOUN   NOUN\n",
      "park      NOUN     NOUN     NOUN   NOUN\n",
      ".        PUNCT    PUNCT    PUNCT  PUNCT\n",
      "length =  10\n",
      "\n",
      "\n",
      "sentence 2\n",
      "      SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "At         ADV      ADV      ADV    ADV\n",
      "least      ADV      ADJ      ADV    ADV\n",
      "two        NUM      NUM      NUM    NUM\n",
      "men       NOUN     NOUN     NOUN   NOUN\n",
      "broke     VERB     VERB     VERB   VERB\n",
      "in         ADP      ADP      ADP    ADV\n",
      "and      CCONJ    CCONJ    CCONJ  CCONJ\n",
      "stole     VERB     VERB     VERB   VERB\n",
      "my         DET      DET      DET   PRON\n",
      "TV        NOUN     NOUN     NOUN   NOUN\n",
      ".        PUNCT    PUNCT    PUNCT  PUNCT\n",
      "length =  11\n",
      "\n",
      "\n",
      "sentence 7\n",
      "         SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "It           PRON     PRON     PRON   PRON\n",
      "was           AUX      AUX      AUX    AUX\n",
      "my            DET      DET      DET   PRON\n",
      "aunt         NOUN     NOUN     NOUN   NOUN\n",
      "’s           PART     PART     PART   PART\n",
      "car          NOUN     NOUN     NOUN   NOUN\n",
      "which         DET      DET      DET   PRON\n",
      "we           PRON     PRON     PRON   PRON\n",
      "sold         VERB     VERB     VERB   VERB\n",
      "at            ADP      ADP      ADP    ADP\n",
      "auction      NOUN     NOUN     NOUN   NOUN\n",
      "last          ADJ      ADJ      ADJ    ADJ\n",
      "year         NOUN     NOUN     NOUN   NOUN\n",
      "in            ADP      ADP      ADP    ADP\n",
      "February    PROPN    PROPN    PROPN  PROPN\n",
      ".           PUNCT    PUNCT    PUNCT  PUNCT\n",
      "length =  16\n",
      "\n",
      "\n",
      "sentence 8\n",
      "        SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "The          DET      DET      DET    DET\n",
      "only         ADJ      ADJ      ADJ    ADJ\n",
      "rabbit      NOUN     NOUN     NOUN   NOUN\n",
      "that         DET      DET      DET   PRON\n",
      "I           PRON     PRON     PRON   PRON\n",
      "ever         ADV      ADV      ADV    ADV\n",
      "liked       VERB     VERB     VERB   VERB\n",
      "was          AUX      AUX      AUX    AUX\n",
      "eaten       VERB     VERB     VERB   VERB\n",
      "by           ADP      ADP      ADP    ADP\n",
      "my           DET      DET      DET   PRON\n",
      "parents     NOUN     NOUN     NOUN   NOUN\n",
      "one          NUM      NUM      NUM    NUM\n",
      "summer      NOUN     NOUN     NOUN   NOUN\n",
      ".          PUNCT    PUNCT    PUNCT  PUNCT\n",
      "length =  15\n",
      "\n",
      "\n",
      "sentence 10\n",
      "             SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "Natural           ADJ      ADJ      ADJ    ADJ\n",
      "disasters        NOUN     NOUN     NOUN   NOUN\n",
      "–               PUNCT    PUNCT    PUNCT  PUNCT\n",
      "storms           NOUN     NOUN     NOUN   NOUN\n",
      ",               PUNCT    PUNCT    PUNCT  PUNCT\n",
      "flooding         NOUN     NOUN     NOUN   NOUN\n",
      ",               PUNCT    PUNCT    PUNCT  PUNCT\n",
      "hurricanes       NOUN     NOUN     NOUN   NOUN\n",
      "–               PUNCT    PUNCT    PUNCT  PUNCT\n",
      "occur            VERB     VERB     VERB   VERB\n",
      "infrequently      ADV      ADV      ADV    ADV\n",
      "but             CCONJ    CCONJ    CCONJ  CCONJ\n",
      "cause            VERB     VERB     VERB   VERB\n",
      "devastation      NOUN     NOUN     NOUN   NOUN\n",
      "that              DET    SCONJ      DET   PRON\n",
      "strains          VERB     VERB     VERB   VERB\n",
      "resources        NOUN     NOUN     NOUN   NOUN\n",
      "to                ADP      ADP      ADP    ADP\n",
      "breaking         NOUN     VERB     NOUN   NOUN\n",
      "point            NOUN     NOUN     NOUN   NOUN\n",
      ".               PUNCT    PUNCT    PUNCT  PUNCT\n",
      "length =  21\n",
      "\n",
      "\n",
      "sentence 12\n",
      "            SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "It              PRON     PRON     PRON   PRON\n",
      "wo              VERB     VERB     VERB    AUX\n",
      "n’t             PART     PART     PART   PART\n",
      "rain            VERB     VERB     VERB   VERB\n",
      "but            CCONJ    CCONJ    CCONJ  CCONJ\n",
      "there           PRON     PRON     PRON   PRON\n",
      "might           VERB     VERB     VERB    AUX\n",
      "be               AUX      AUX      AUX   VERB\n",
      "snow            NOUN     NOUN     NOUN   NOUN\n",
      "on               ADP      ADP      ADP    ADP\n",
      "high             ADJ      ADJ      ADJ    ADJ\n",
      "ground          NOUN     NOUN     NOUN   NOUN\n",
      "if             SCONJ    SCONJ    SCONJ  SCONJ\n",
      "the              DET      DET      DET    DET\n",
      "temperature     NOUN     NOUN     NOUN   NOUN\n",
      "stays           VERB     VERB     VERB   VERB\n",
      "about            ADP      ADP      ADP    ADP\n",
      "the              DET      DET      DET    DET\n",
      "same             ADJ      ADJ      ADJ    ADJ\n",
      "over             ADP      ADP      ADP    ADP\n",
      "the              DET      DET      DET    DET\n",
      "next             ADJ      ADJ      ADJ    ADJ\n",
      "24               NUM      NUM      NUM    NUM\n",
      "hours           NOUN     NOUN     NOUN   NOUN\n",
      ".              PUNCT    PUNCT    PUNCT  PUNCT\n",
      "length =  25\n",
      "\n",
      "\n",
      "sentence 15\n",
      "              SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "English          PROPN    PROPN    PROPN  PROPN\n",
      "also               ADV      ADV      ADV    ADV\n",
      "has                AUX      AUX      AUX   VERB\n",
      "many               ADJ      ADJ      ADJ    ADJ\n",
      "words             NOUN     NOUN     NOUN   NOUN\n",
      "of                 ADP      ADP      ADP    ADP\n",
      "more               ADJ      ADV      ADJ    ADJ\n",
      "or               CCONJ    CCONJ    CCONJ  CCONJ\n",
      "less               ADV      ADV      ADV    ADV\n",
      "unique             ADJ      ADJ      ADJ    ADJ\n",
      "function          NOUN     NOUN     NOUN   NOUN\n",
      ",                PUNCT    PUNCT    PUNCT  PUNCT\n",
      "including         VERB     VERB     VERB   VERB\n",
      "interjections     NOUN     NOUN     NOUN   NOUN\n",
      "(                PUNCT    PUNCT    PUNCT  PUNCT\n",
      "oh                INTJ     INTJ     INTJ   INTJ\n",
      ",                PUNCT    PUNCT    PUNCT  PUNCT\n",
      "ah                INTJ     INTJ     INTJ   INTJ\n",
      ")                PUNCT    PUNCT    PUNCT  PUNCT\n",
      ",                PUNCT    PUNCT    PUNCT  PUNCT\n",
      "negatives        PROPN     NOUN     NOUN   NOUN\n",
      "(                PUNCT    PUNCT    PUNCT  PUNCT\n",
      "no                INTJ     INTJ     INTJ   INTJ\n",
      ",                PUNCT    PUNCT    PUNCT  PUNCT\n",
      "not               PART     PART     PART   PART\n",
      ")                PUNCT    PUNCT    PUNCT  PUNCT\n",
      ",                PUNCT    PUNCT    PUNCT  PUNCT\n",
      "politeness        NOUN     NOUN     NOUN   NOUN\n",
      "markers           NOUN     NOUN     NOUN   NOUN\n",
      "(                PUNCT    PUNCT    PUNCT  PUNCT\n",
      "please            INTJ     INTJ     INTJ   INTJ\n",
      ",                PUNCT    PUNCT    PUNCT  PUNCT\n",
      "thank             VERB     VERB     VERB   VERB\n",
      "you               PRON     PRON     PRON   PRON\n",
      ")                PUNCT    PUNCT    PUNCT  PUNCT\n",
      ",                PUNCT    PUNCT    PUNCT  PUNCT\n",
      "and              CCONJ    CCONJ    CCONJ  CCONJ\n",
      "the                DET      DET      DET    DET\n",
      "existential        ADJ      ADJ      ADJ    ADJ\n",
      "‘                PUNCT    PUNCT    PUNCT  PUNCT\n",
      "there             PRON      ADV      ADV    ADV\n",
      "’                PUNCT    PUNCT    PUNCT  PUNCT\n",
      "(                PUNCT    PUNCT    PUNCT  PUNCT\n",
      "there             PRON     PRON     PRON   PRON\n",
      "are                AUX      AUX      AUX   VERB\n",
      "horses            NOUN     NOUN     NOUN   NOUN\n",
      "but              CCONJ    CCONJ    CCONJ  CCONJ\n",
      "not               PART     PART     PART   PART\n",
      "unicorns          NOUN     NOUN     NOUN   NOUN\n",
      ")                PUNCT    PUNCT    PUNCT  PUNCT\n",
      "among              ADP      ADP      ADP    ADP\n",
      "others            NOUN     NOUN     NOUN   NOUN\n",
      ".                PUNCT    PUNCT    PUNCT  PUNCT\n",
      "length =  53\n",
      "\n",
      "\n",
      "sentence 17\n",
      "          SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "The            DET      DET      DET    DET\n",
      "Penn         PROPN    PROPN    PROPN  PROPN\n",
      "Treebank     PROPN    PROPN    PROPN  PROPN\n",
      "tagset        NOUN     NOUN     NOUN   NOUN\n",
      "was            AUX      AUX      AUX    AUX\n",
      "culled        VERB     VERB     VERB   VERB\n",
      "from           ADP      ADP      ADP    ADP\n",
      "the            DET      DET      DET    DET\n",
      "original       ADJ      ADJ      ADJ    ADJ\n",
      "87tag         NOUN    PROPN     NOUN   NOUN\n",
      "tagset        NOUN     NOUN    PROPN   NOUN\n",
      "for            ADP      ADP      ADP    ADP\n",
      "the            DET      DET      DET    DET\n",
      "Brown        PROPN    PROPN    PROPN  PROPN\n",
      "Corpus       PROPN    PROPN    PROPN  PROPN\n",
      ".            PUNCT    PUNCT    PUNCT  PUNCT\n",
      "For            ADP      ADP      ADP    ADP\n",
      "example       NOUN     NOUN     NOUN   NOUN\n",
      "the            DET      DET      DET    DET\n",
      "original       ADJ      ADJ      ADJ    ADJ\n",
      "Brown        PROPN    PROPN    PROPN  PROPN\n",
      "and          CCONJ    CCONJ    CCONJ  CCONJ\n",
      "C5           PROPN    PROPN    PROPN  PROPN\n",
      "tagsets       NOUN     NOUN     NOUN   NOUN\n",
      "include       VERB     VERB     VERB   VERB\n",
      "a              DET      DET      DET    DET\n",
      "separate       ADJ      ADJ      ADJ    ADJ\n",
      "tag           NOUN     NOUN     NOUN   NOUN\n",
      "for            ADP      ADP      ADP    ADP\n",
      "each           DET      DET      DET    DET\n",
      "of             ADP      ADP      ADP    ADP\n",
      "the            DET      DET      DET    DET\n",
      "different      ADJ      ADJ      ADJ    ADJ\n",
      "forms         NOUN     NOUN     NOUN   NOUN\n",
      "of             ADP      ADP      ADP    ADP\n",
      "the            DET      DET      DET    DET\n",
      "verbs         NOUN     NOUN     NOUN   NOUN\n",
      "do             AUX      AUX      AUX   VERB\n",
      "(            PUNCT    PUNCT    PUNCT  PUNCT\n",
      "e.g.           ADV      ADV      ADV      X\n",
      "C5            NOUN     NOUN     NOUN   NOUN\n",
      "tag           NOUN     NOUN     NOUN   NOUN\n",
      "VDD          PROPN    PROPN    PROPN   NOUN\n",
      "for            ADP      ADP      ADP    ADP\n",
      "did           NOUN     NOUN      AUX   VERB\n",
      "and          CCONJ    CCONJ    CCONJ  CCONJ\n",
      "VDG          PROPN    PROPN    PROPN   NOUN\n",
      "tag           NOUN     NOUN     NOUN   NOUN\n",
      "for            ADP      ADP      ADP  SCONJ\n",
      "doing         VERB     VERB     VERB   VERB\n",
      ")            PUNCT    PUNCT    PUNCT  PUNCT\n",
      ",            PUNCT    PUNCT    PUNCT  PUNCT\n",
      "be             AUX      AUX      AUX   VERB\n",
      "and          CCONJ    CCONJ    CCONJ  CCONJ\n",
      "have           AUX      AUX      AUX   VERB\n",
      ".            PUNCT    PUNCT    PUNCT  PUNCT\n",
      "length =  56\n",
      "\n",
      "\n",
      "sentence 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "Thus            ADV      ADV      ADV    ADV\n",
      "the             DET      DET      DET    DET\n",
      "EM             NOUN     NOUN    PROPN  PROPN\n",
      "-             PUNCT    PUNCT    PUNCT  PUNCT\n",
      "trained        VERB     VERB     VERB   VERB\n",
      "“             PUNCT    PUNCT    PUNCT  PUNCT\n",
      "pure            ADJ      ADJ      ADJ    ADJ\n",
      "HMM           PROPN     NOUN     NOUN   INTJ\n",
      "”             PUNCT    PUNCT    PUNCT  PUNCT\n",
      "tagger         NOUN     NOUN     NOUN   NOUN\n",
      "is              AUX      AUX      AUX    AUX\n",
      "probably        ADV      ADV      ADV    ADV\n",
      "best            ADV      ADV      ADV    ADV\n",
      "suited          ADJ      ADJ      ADJ   VERB\n",
      "to              ADP      ADP      ADP    ADP\n",
      "cases          NOUN     NOUN     NOUN   NOUN\n",
      "where           ADV      ADV      ADV    ADV\n",
      "no              DET      DET      DET    DET\n",
      "training       NOUN     NOUN     NOUN   NOUN\n",
      "data           NOUN     NOUN     NOUN   NOUN\n",
      "is              AUX      AUX      AUX    AUX\n",
      "available       ADJ      ADJ      ADJ    ADJ\n",
      ",             PUNCT    PUNCT    PUNCT  PUNCT\n",
      "for             ADP      ADP      ADP    ADP\n",
      "example        NOUN     NOUN     NOUN   NOUN\n",
      ",             PUNCT    PUNCT    PUNCT  PUNCT\n",
      "when            ADV      ADV      ADV    ADV\n",
      "tagging        VERB     VERB     VERB   VERB\n",
      "languages      NOUN     NOUN     NOUN   NOUN\n",
      "for             ADP      ADP      ADP    ADP\n",
      "which           DET      DET      DET   PRON\n",
      "no              DET      DET      DET    DET\n",
      "data           NOUN     NOUN     NOUN   NOUN\n",
      "was             AUX      AUX      AUX    AUX\n",
      "previously      ADV      ADV      ADV    ADV\n",
      "hand           NOUN     NOUN     NOUN   NOUN\n",
      "-             PUNCT    PUNCT    PUNCT  PUNCT\n",
      "tagged         VERB     VERB     VERB   VERB\n",
      ".             PUNCT    PUNCT    PUNCT  PUNCT\n",
      "length =  39\n",
      "\n",
      "\n",
      "sentence 21\n",
      "              SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "Skill             NOUN     NOUN     NOUN   NOUN\n",
      "without            ADP      ADP      ADP    ADP\n",
      "imagination       NOUN     NOUN     NOUN   NOUN\n",
      "is                 AUX      AUX      AUX    AUX\n",
      "craftsmanship     NOUN     NOUN     NOUN   NOUN\n",
      "and              CCONJ    CCONJ    CCONJ  CCONJ\n",
      "gives             VERB     VERB     VERB   VERB\n",
      "us                PRON     PRON     PRON   PRON\n",
      "many               ADJ      ADJ      ADJ    ADJ\n",
      "useful             ADJ      ADJ      ADJ    ADJ\n",
      "objects           NOUN     NOUN     NOUN   NOUN\n",
      "such               ADJ      ADJ      ADJ    ADJ\n",
      "as               SCONJ    SCONJ    SCONJ    ADP\n",
      "wickerwork        NOUN     NOUN     NOUN    ADJ\n",
      "picnic            NOUN     NOUN     NOUN   NOUN\n",
      "baskets           NOUN     NOUN     NOUN   NOUN\n",
      ".                PUNCT    PUNCT    PUNCT  PUNCT\n",
      "Imagination       NOUN     NOUN     NOUN   NOUN\n",
      "without            ADP      ADP      ADP    ADP\n",
      "skill             NOUN     NOUN     NOUN   NOUN\n",
      "gives             VERB     VERB     VERB   VERB\n",
      "us                PRON     PRON     PRON   PRON\n",
      "modern             ADJ      ADJ      ADJ    ADJ\n",
      "art               NOUN     NOUN     NOUN   NOUN\n",
      ".                PUNCT    PUNCT    PUNCT  PUNCT\n",
      "length =  25\n",
      "\n",
      "\n",
      "sentence 23\n",
      "            SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "But            CCONJ    CCONJ    CCONJ  CCONJ\n",
      "far              ADV      ADV      ADV    ADV\n",
      "fewer            ADJ      ADJ      ADJ    ADJ\n",
      "people          NOUN     NOUN     NOUN   NOUN\n",
      "fully            ADV      ADV      ADV    ADV\n",
      "understand      VERB     VERB     VERB   VERB\n",
      "how              ADV      ADV      ADV    ADV\n",
      "the              DET      DET      DET    DET\n",
      "Media          PROPN    PROPN    PROPN   NOUN\n",
      "Lab            PROPN    PROPN    PROPN  PROPN\n",
      "operates        VERB     VERB     VERB   VERB\n",
      ",              PUNCT    PUNCT    PUNCT  PUNCT\n",
      "fits            VERB     VERB     VERB   VERB\n",
      "into             ADP      ADP      ADP    ADP\n",
      "MIT            PROPN    PROPN    PROPN  PROPN\n",
      ",              PUNCT    PUNCT    PUNCT  PUNCT\n",
      "and            CCONJ    CCONJ    CCONJ  CCONJ\n",
      "encourages      VERB     VERB     VERB   VERB\n",
      "such             DET      DET      DET    DET\n",
      "a                DET      DET      DET    DET\n",
      "creative         ADJ      ADJ      ADJ    ADJ\n",
      "environment     NOUN     NOUN     NOUN   NOUN\n",
      ";              PUNCT    PUNCT    PUNCT  PUNCT\n",
      "about            ADP      ADP      ADP    ADV\n",
      "half            NOUN     NOUN     NOUN   NOUN\n",
      "of               ADP      ADP      ADP    ADP\n",
      "the              DET      DET      DET    DET\n",
      "anniversary     NOUN     NOUN     NOUN    ADJ\n",
      "celebration     NOUN     NOUN     NOUN   NOUN\n",
      "’s              PART     PART     PART   PART\n",
      "program         NOUN     NOUN     NOUN   NOUN\n",
      "focused         VERB     VERB     VERB   VERB\n",
      "on               ADP      ADP      ADP  SCONJ\n",
      "simply           ADV      ADV      ADV    ADV\n",
      "defining        VERB     VERB     VERB   VERB\n",
      "what            PRON     PRON     PRON   PRON\n",
      "the              DET      DET      DET    DET\n",
      "Media          PROPN    PROPN    PROPN   NOUN\n",
      "Lab            PROPN    PROPN    PROPN   NOUN\n",
      "is               AUX      AUX      AUX    AUX\n",
      ".              PUNCT    PUNCT    PUNCT  PUNCT\n",
      "length =  41\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Implement the method comparison_pos(number):\n",
    "for i in range(len(texts)):\n",
    "    comparison_pos(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make comparison tables of \"Tag\" of SpaCy and Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to make comparison tables of \"Tag\" of SpaCy and Stanza\n",
    "def comparison_tag(number):\n",
    "    text = texts[number]\n",
    "    sentence_number = sentence_numbers[number]\n",
    "    print('sentence' , sentence_number)    \n",
    "\n",
    "    spacy = []\n",
    "    spacy_index = []\n",
    "    spacy_pos = []\n",
    "    spacy_tag =[]\n",
    "    spacy_dep = []\n",
    "    spacy_head = []\n",
    "\n",
    "    doc_spacy = nlp_spacy_sm(text)\n",
    "    for d in doc_spacy:\n",
    "        spacy_index.append((d.text))\n",
    "        spacy_pos.append((d.pos_))\n",
    "        spacy_tag.append((d.tag_))\n",
    "        spacy_dep.append((d.dep_))\n",
    "        spacy_head.append((d.head))\n",
    "\n",
    "    spacy.append(spacy_pos)\n",
    "    spacy.append(spacy_tag)\n",
    "    spacy.append(spacy_dep)\n",
    "    spacy.append(spacy_head)\n",
    "\n",
    "    df_spacy_sm = pd.DataFrame(spacy,\n",
    "                      index=['pos', 'tag', 'dep', 'head'],\n",
    "                      columns=spacy_index)\n",
    "    df_spacy_sm = df_spacy_sm.T\n",
    "\n",
    "    spacy = []\n",
    "    spacy_index = []\n",
    "    spacy_pos = []\n",
    "    spacy_tag =[]\n",
    "    spacy_dep = []\n",
    "    spacy_head = []\n",
    "\n",
    "    doc_spacy = nlp_spacy_md(text)\n",
    "    for d in doc_spacy:\n",
    "        spacy_index.append((d.text))\n",
    "        spacy_pos.append((d.pos_))\n",
    "        spacy_tag.append((d.tag_))\n",
    "        spacy_dep.append((d.dep_))\n",
    "        spacy_head.append((d.head))\n",
    "\n",
    "    spacy.append(spacy_pos)\n",
    "    spacy.append(spacy_tag)\n",
    "    spacy.append(spacy_dep)\n",
    "    spacy.append(spacy_head)\n",
    "\n",
    "    df_spacy_md = pd.DataFrame(spacy,\n",
    "                      index=['pos', 'tag', 'dep', 'head'],\n",
    "                      columns=spacy_index)\n",
    "    df_spacy_md = df_spacy_md.T\n",
    "\n",
    "    spacy = []\n",
    "    spacy_index = []\n",
    "    spacy_pos = []\n",
    "    spacy_tag =[]\n",
    "    spacy_dep = []\n",
    "    spacy_head = []\n",
    "\n",
    "    doc_spacy = nlp_spacy_lg(text)\n",
    "    for d in doc_spacy:\n",
    "        spacy_index.append((d.text))\n",
    "        spacy_pos.append((d.pos_))\n",
    "        spacy_tag.append((d.tag_))\n",
    "        spacy_dep.append((d.dep_))\n",
    "        spacy_head.append((d.head))\n",
    "\n",
    "    spacy.append(spacy_pos)\n",
    "    spacy.append(spacy_tag)\n",
    "    spacy.append(spacy_dep)\n",
    "    spacy.append(spacy_head)\n",
    "\n",
    "    df_spacy_lg = pd.DataFrame(spacy,\n",
    "                      index=['pos', 'tag', 'dep', 'head'],\n",
    "                      columns=spacy_index)\n",
    "    df_spacy_lg = df_spacy_lg.T\n",
    "\n",
    "    stanza = []\n",
    "    stanza_index = []\n",
    "    stanza_pos = []\n",
    "    stanza_tag =[]\n",
    "    stanza_dep = []\n",
    "    stanza_head = []\n",
    "\n",
    "    doc_stanza = nlp_stanza(text)\n",
    "    sentence_number = len(doc_stanza.sentences)\n",
    "    \n",
    "    for i in range(sentence_number):\n",
    "        sentence = doc_stanza.sentences[i]\n",
    "        for token in sentence.tokens:\n",
    "            stanza_index.append(token.words[0].text)\n",
    "            stanza_pos.append(token.words[0].upos)\n",
    "            stanza_tag.append(token.words[0].xpos)\n",
    "            stanza_dep.append(token.words[0].deprel)\n",
    "            stanza_head.append(sentence.tokens[token.words[0].head-1].words[0].text)\n",
    "    \n",
    "    stanza.append(stanza_pos)\n",
    "    stanza.append(stanza_tag)\n",
    "    stanza.append(stanza_dep)\n",
    "    stanza.append(stanza_head)\n",
    "\n",
    "    df_stanza = pd.DataFrame(stanza,\n",
    "                      index=['pos', 'tag', 'dep', 'head'],\n",
    "                      columns=stanza_index)\n",
    "    df_stanza = df_stanza.T\n",
    "    \n",
    "    df_tag = pd.concat([df_spacy_sm['tag'], df_spacy_md['tag'],df_spacy_lg['tag'], df_stanza['tag']], axis=1, join='outer')\n",
    "    df_tag.columns = ['SpaCy_sm', 'SpaCy_md', 'SpaCy_lg', 'Stanza']\n",
    "    print(df_tag)\n",
    "    print('length = ',len(df_tag))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence 1\n",
      "      SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "The         DT       DT       DT     DT\n",
      "old         JJ       JJ       JJ     JJ\n",
      "car         NN       NN       NN     NN\n",
      "broke      VBD      VBD      VBD    VBD\n",
      "down        RP       RP       RP     RP\n",
      "in          IN       IN       IN     IN\n",
      "the         DT       DT       DT     DT\n",
      "car         NN       NN       NN     NN\n",
      "park        NN       NN       NN     NN\n",
      ".            .        .        .      .\n",
      "length =  10\n",
      "\n",
      "\n",
      "sentence 2\n",
      "      SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "At          RB       RB       RB     RB\n",
      "least      RBS      JJS      RBS    RBS\n",
      "two         CD       CD       CD     CD\n",
      "men        NNS      NNS      NNS    NNS\n",
      "broke      VBD      VBD      VBD    VBD\n",
      "in          RP       RP       RP     RB\n",
      "and         CC       CC       CC     CC\n",
      "stole      VBD      VBD      VBD    VBD\n",
      "my        PRP$     PRP$     PRP$   PRP$\n",
      "TV          NN       NN       NN     NN\n",
      ".            .        .        .      .\n",
      "length =  11\n",
      "\n",
      "\n",
      "sentence 7\n",
      "         SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "It            PRP      PRP      PRP    PRP\n",
      "was           VBD      VBD      VBD    VBD\n",
      "my           PRP$     PRP$     PRP$   PRP$\n",
      "aunt           NN       NN       NN     NN\n",
      "’s            POS      POS      POS    POS\n",
      "car            NN       NN       NN     NN\n",
      "which         WDT      WDT      WDT    WDT\n",
      "we            PRP      PRP      PRP    PRP\n",
      "sold          VBD      VBD      VBD    VBD\n",
      "at             IN       IN       IN     IN\n",
      "auction        NN       NN       NN     NN\n",
      "last           JJ       JJ       JJ     JJ\n",
      "year           NN       NN       NN     NN\n",
      "in             IN       IN       IN     IN\n",
      "February      NNP      NNP      NNP    NNP\n",
      ".               .        .        .      .\n",
      "length =  16\n",
      "\n",
      "\n",
      "sentence 8\n",
      "        SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "The           DT       DT       DT     DT\n",
      "only          JJ       JJ       JJ     JJ\n",
      "rabbit        NN       NN       NN     NN\n",
      "that         WDT      WDT      WDT    WDT\n",
      "I            PRP      PRP      PRP    PRP\n",
      "ever          RB       RB       RB     RB\n",
      "liked        VBD      VBD      VBD    VBD\n",
      "was          VBD      VBD      VBD    VBD\n",
      "eaten        VBN      VBN      VBN    VBN\n",
      "by            IN       IN       IN     IN\n",
      "my          PRP$     PRP$     PRP$   PRP$\n",
      "parents      NNS      NNS      NNS    NNS\n",
      "one           CD       CD       CD     CD\n",
      "summer        NN       NN       NN     NN\n",
      ".              .        .        .      .\n",
      "length =  15\n",
      "\n",
      "\n",
      "sentence 10\n",
      "             SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "Natural            JJ       JJ       JJ     JJ\n",
      "disasters         NNS      NNS      NNS    NNS\n",
      "–                   :        :        :      ,\n",
      "storms            NNS      NNS      NNS    NNS\n",
      ",                   ,        ,        ,      ,\n",
      "flooding           NN       NN       NN     NN\n",
      ",                   ,        ,        ,      ,\n",
      "hurricanes        NNS      NNS      NNS    NNS\n",
      "–                   :        :        :      ,\n",
      "occur             VBP      VBP      VBP    VBP\n",
      "infrequently       RB       RB       RB     RB\n",
      "but                CC       CC       CC     CC\n",
      "cause             VBP       VB       VB    VBP\n",
      "devastation        NN       NN       NN     NN\n",
      "that              WDT       IN      WDT    WDT\n",
      "strains           VBZ      VBZ      VBZ    VBZ\n",
      "resources         NNS      NNS      NNS    NNS\n",
      "to                 IN       IN       IN     IN\n",
      "breaking           NN      VBG       NN     NN\n",
      "point              NN       NN       NN     NN\n",
      ".                   .        .        .      .\n",
      "length =  21\n",
      "\n",
      "\n",
      "sentence 12\n",
      "            SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "It               PRP      PRP      PRP    PRP\n",
      "wo                MD       MD       MD     MD\n",
      "n’t               RB       RB       RB     RB\n",
      "rain              VB       VB       VB     VB\n",
      "but               CC       CC       CC     CC\n",
      "there             EX       EX       EX     EX\n",
      "might             MD       MD       MD     MD\n",
      "be                VB       VB       VB     VB\n",
      "snow              NN       NN       NN     NN\n",
      "on                IN       IN       IN     IN\n",
      "high              JJ       JJ       JJ     JJ\n",
      "ground            NN       NN       NN     NN\n",
      "if                IN       IN       IN     IN\n",
      "the               DT       DT       DT     DT\n",
      "temperature       NN       NN       NN     NN\n",
      "stays            VBZ      VBZ      VBZ    VBZ\n",
      "about             IN       IN       IN     IN\n",
      "the               DT       DT       DT     DT\n",
      "same              JJ       JJ       JJ     JJ\n",
      "over              IN       IN       IN     IN\n",
      "the               DT       DT       DT     DT\n",
      "next              JJ       JJ       JJ     JJ\n",
      "24                CD       CD       CD     CD\n",
      "hours            NNS      NNS      NNS    NNS\n",
      ".                  .        .        .      .\n",
      "length =  25\n",
      "\n",
      "\n",
      "sentence 15\n",
      "              SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "English            NNP      NNP      NNP    NNP\n",
      "also                RB       RB       RB     RB\n",
      "has                VBZ      VBZ      VBZ    VBZ\n",
      "many                JJ       JJ       JJ     JJ\n",
      "words              NNS      NNS      NNS    NNS\n",
      "of                  IN       IN       IN     IN\n",
      "more               JJR      RBR      JJR    JJR\n",
      "or                  CC       CC       CC     CC\n",
      "less               RBR      RBR      RBR    RBR\n",
      "unique              JJ       JJ       JJ     JJ\n",
      "function            NN       NN       NN     NN\n",
      ",                    ,        ,        ,      ,\n",
      "including          VBG      VBG      VBG    VBG\n",
      "interjections      NNS      NNS      NNS    NNS\n",
      "(                -LRB-    -LRB-    -LRB-  -LRB-\n",
      "oh                  UH       UH       UH     UH\n",
      ",                    ,        ,        ,      ,\n",
      "ah                  UH       UH       UH     UH\n",
      ")                -RRB-    -RRB-    -RRB-  -RRB-\n",
      ",                    ,        ,        ,      ,\n",
      "negatives          NNP      NNS      NNS    NNS\n",
      "(                -LRB-    -LRB-    -LRB-  -LRB-\n",
      "no                  UH       UH       UH     UH\n",
      ",                    ,        ,        ,      ,\n",
      "not                 RB       RB       RB     RB\n",
      ")                -RRB-    -RRB-    -RRB-  -RRB-\n",
      ",                    ,        ,        ,      ,\n",
      "politeness          NN       NN       NN     NN\n",
      "markers            NNS      NNS      NNS    NNS\n",
      "(                -LRB-    -LRB-    -LRB-  -LRB-\n",
      "please              UH       UH       UH     UH\n",
      ",                    ,        ,        ,      ,\n",
      "thank              VBP      VBP      VBP    VBP\n",
      "you                PRP      PRP      PRP    PRP\n",
      ")                -RRB-    -RRB-    -RRB-  -RRB-\n",
      ",                    ,        ,        ,      ,\n",
      "and                 CC       CC       CC     CC\n",
      "the                 DT       DT       DT     DT\n",
      "existential         JJ       JJ       JJ     JJ\n",
      "‘                   ``       ``       ``     ``\n",
      "there               EX       RB       RB     RB\n",
      "’                   ''       ''       ''     ''\n",
      "(                -LRB-    -LRB-    -LRB-  -LRB-\n",
      "there               EX       EX       EX     EX\n",
      "are                VBP      VBP      VBP    VBP\n",
      "horses             NNS      NNS      NNS    NNS\n",
      "but                 CC       CC       CC     CC\n",
      "not                 RB       RB       RB     RB\n",
      "unicorns           NNS      NNS      NNS    NNS\n",
      ")                -RRB-    -RRB-    -RRB-  -RRB-\n",
      "among               IN       IN       IN     IN\n",
      "others             NNS      NNS      NNS    NNS\n",
      ".                    .        .        .      .\n",
      "length =  53\n",
      "\n",
      "\n",
      "sentence 17\n",
      "          SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "The             DT       DT       DT     DT\n",
      "Penn           NNP      NNP      NNP    NNP\n",
      "Treebank       NNP      NNP      NNP    NNP\n",
      "tagset          NN       NN       NN     NN\n",
      "was            VBD      VBD      VBD    VBD\n",
      "culled         VBN      VBN      VBN    VBN\n",
      "from            IN       IN       IN     IN\n",
      "the             DT       DT       DT     DT\n",
      "original        JJ       JJ       JJ     JJ\n",
      "87tag           NN      NNP       NN     NN\n",
      "tagset          NN       NN      NNP     NN\n",
      "for             IN       IN       IN     IN\n",
      "the             DT       DT       DT     DT\n",
      "Brown          NNP      NNP      NNP    NNP\n",
      "Corpus         NNP      NNP      NNP    NNP\n",
      ".                .        .        .      .\n",
      "For             IN       IN       IN     IN\n",
      "example         NN       NN       NN     NN\n",
      "the             DT       DT       DT     DT\n",
      "original        JJ       JJ       JJ     JJ\n",
      "Brown          NNP      NNP      NNP    NNP\n",
      "and             CC       CC       CC     CC\n",
      "C5             NNP      NNP      NNP    NNP\n",
      "tagsets        NNS      NNS      NNS    NNS\n",
      "include        VBP      VBP      VBP    VBP\n",
      "a               DT       DT       DT     DT\n",
      "separate        JJ       JJ       JJ     JJ\n",
      "tag             NN       NN       NN     NN\n",
      "for             IN       IN       IN     IN\n",
      "each            DT       DT       DT     DT\n",
      "of              IN       IN       IN     IN\n",
      "the             DT       DT       DT     DT\n",
      "different       JJ       JJ       JJ     JJ\n",
      "forms          NNS      NNS      NNS    NNS\n",
      "of              IN       IN       IN     IN\n",
      "the             DT       DT       DT     DT\n",
      "verbs          NNS      NNS      NNS    NNS\n",
      "do             VBP       VB      VBP    VBP\n",
      "(            -LRB-    -LRB-    -LRB-  -LRB-\n",
      "e.g.            RB       RB       RB     FW\n",
      "C5              NN       NN       NN     NN\n",
      "tag             NN       NN       NN     NN\n",
      "VDD            NNP      NNP      NNP     NN\n",
      "for             IN       IN       IN     IN\n",
      "did             NN       NN      VBD    VBN\n",
      "and             CC       CC       CC     CC\n",
      "VDG            NNP      NNP      NNP     NN\n",
      "tag             NN       NN       NN     NN\n",
      "for             IN       IN       IN     IN\n",
      "doing          VBG      VBG      VBG    VBG\n",
      ")            -RRB-    -RRB-    -RRB-  -RRB-\n",
      ",                ,        ,        ,      ,\n",
      "be              VB       VB       VB     VB\n",
      "and             CC       CC       CC     CC\n",
      "have            VB       VB       VB     VB\n",
      ".                .        .        .      .\n",
      "length =  56\n",
      "\n",
      "\n",
      "sentence 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "Thus             RB       RB       RB     RB\n",
      "the              DT       DT       DT     DT\n",
      "EM               NN       NN      NNP    NNP\n",
      "-              HYPH     HYPH     HYPH   HYPH\n",
      "trained         VBN      VBN      VBN    VBN\n",
      "“                ``       ``       ``     ``\n",
      "pure             JJ       JJ       JJ     JJ\n",
      "HMM             NNP       NN       NN     UH\n",
      "”                ''       ''       ''     ''\n",
      "tagger           NN       NN       NN     NN\n",
      "is              VBZ      VBZ      VBZ    VBZ\n",
      "probably         RB       RB       RB     RB\n",
      "best             RB      RBS       RB    RBS\n",
      "suited           JJ       JJ       JJ    VBN\n",
      "to               IN       IN       IN     IN\n",
      "cases           NNS      NNS      NNS    NNS\n",
      "where           WRB      WRB      WRB    WRB\n",
      "no               DT       DT       DT     DT\n",
      "training         NN       NN       NN     NN\n",
      "data            NNS      NNS      NNS     NN\n",
      "is              VBZ      VBZ      VBZ    VBZ\n",
      "available        JJ       JJ       JJ     JJ\n",
      ",                 ,        ,        ,      ,\n",
      "for              IN       IN       IN     IN\n",
      "example          NN       NN       NN     NN\n",
      ",                 ,        ,        ,      ,\n",
      "when            WRB      WRB      WRB    WRB\n",
      "tagging         VBG      VBG      VBG    VBG\n",
      "languages       NNS      NNS      NNS    NNS\n",
      "for              IN       IN       IN     IN\n",
      "which           WDT      WDT      WDT    WDT\n",
      "no               DT       DT       DT     DT\n",
      "data             NN       NN       NN     NN\n",
      "was             VBD      VBD      VBD    VBD\n",
      "previously       RB       RB       RB     RB\n",
      "hand             NN       NN       NN     NN\n",
      "-              HYPH     HYPH     HYPH   HYPH\n",
      "tagged          VBN      VBN      VBN    VBN\n",
      ".                 .        .        .      .\n",
      "length =  39\n",
      "\n",
      "\n",
      "sentence 21\n",
      "              SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "Skill               NN       NN       NN     NN\n",
      "without             IN       IN       IN     IN\n",
      "imagination         NN       NN       NN     NN\n",
      "is                 VBZ      VBZ      VBZ    VBZ\n",
      "craftsmanship       NN       NN       NN     NN\n",
      "and                 CC       CC       CC     CC\n",
      "gives              VBZ      VBZ      VBZ    VBZ\n",
      "us                 PRP      PRP      PRP    PRP\n",
      "many                JJ       JJ       JJ     JJ\n",
      "useful              JJ       JJ       JJ     JJ\n",
      "objects            NNS      NNS      NNS    NNS\n",
      "such                JJ       JJ       JJ     JJ\n",
      "as                  IN       IN       IN     IN\n",
      "wickerwork          NN       NN       NN     JJ\n",
      "picnic              NN       NN       NN     NN\n",
      "baskets            NNS      NNS      NNS    NNS\n",
      ".                    .        .        .      .\n",
      "Imagination         NN       NN       NN     NN\n",
      "without             IN       IN       IN     IN\n",
      "skill               NN       NN       NN     NN\n",
      "gives              VBZ      VBZ      VBZ    VBZ\n",
      "us                 PRP      PRP      PRP    PRP\n",
      "modern              JJ       JJ       JJ     JJ\n",
      "art                 NN       NN       NN     NN\n",
      ".                    .        .        .      .\n",
      "length =  25\n",
      "\n",
      "\n",
      "sentence 23\n",
      "            SpaCy_sm SpaCy_md SpaCy_lg Stanza\n",
      "But               CC       CC       CC     CC\n",
      "far               RB       RB       RB     RB\n",
      "fewer            JJR      JJR      JJR    JJR\n",
      "people           NNS      NNS      NNS    NNS\n",
      "fully             RB       RB       RB     RB\n",
      "understand       VBP      VBP      VBP    VBP\n",
      "how              WRB      WRB      WRB    WRB\n",
      "the               DT       DT       DT     DT\n",
      "Media            NNP      NNP     NNPS     NN\n",
      "Lab              NNP      NNP      NNP    NNP\n",
      "operates         VBZ      VBZ      VBZ    VBZ\n",
      ",                  ,        ,        ,      ,\n",
      "fits             VBZ      VBZ      VBZ    VBZ\n",
      "into              IN       IN       IN     IN\n",
      "MIT              NNP      NNP      NNP    NNP\n",
      ",                  ,        ,        ,      ,\n",
      "and               CC       CC       CC     CC\n",
      "encourages       VBZ      VBZ      VBZ    VBZ\n",
      "such             PDT      PDT      PDT    PDT\n",
      "a                 DT       DT       DT     DT\n",
      "creative          JJ       JJ       JJ     JJ\n",
      "environment       NN       NN       NN     NN\n",
      ";                  :        :        :      ,\n",
      "about             IN       IN       IN     RB\n",
      "half              NN       NN       NN     NN\n",
      "of                IN       IN       IN     IN\n",
      "the               DT       DT       DT     DT\n",
      "anniversary       NN       NN       NN     JJ\n",
      "celebration       NN       NN       NN     NN\n",
      "’s               POS      POS      POS    POS\n",
      "program           NN       NN       NN     NN\n",
      "focused          VBD      VBD      VBD    VBN\n",
      "on                IN       IN       IN     IN\n",
      "simply            RB       RB       RB     RB\n",
      "defining         VBG      VBG      VBG    VBG\n",
      "what              WP       WP       WP     WP\n",
      "the               DT       DT       DT     DT\n",
      "Media            NNP      NNP     NNPS     NN\n",
      "Lab              NNP      NNP      NNP     NN\n",
      "is               VBZ      VBZ      VBZ    VBZ\n",
      ".                  .        .        .      .\n",
      "length =  41\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Implement the method comparison_tag(number):\n",
    "for i in range(len(texts)):\n",
    "    comparison_tag(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
